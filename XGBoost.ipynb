{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost와 Hyper Parameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기본 데이터"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.curdir, 'data')\n",
    "userv2_path = os.path.join(base_path, 'users_v2.csv') # age를 random 추출\n",
    "bookv4_path = os.path.join(base_path, 'books_v4.csv') # 증원님까지 합친 데이터\n",
    "rating_path = os.path.join(base_path, 'train_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                 59803\n",
       "isbn                   129777\n",
       "rating                     10\n",
       "book_title             115473\n",
       "book_author             54716\n",
       "year_of_publication        92\n",
       "publisher                1408\n",
       "img_url                129777\n",
       "language                   24\n",
       "summary                 69758\n",
       "img_path               129777\n",
       "category                   15\n",
       "location                13888\n",
       "age                        91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 불러와서 차원 파악\n",
    "usersv2 = pd.read_csv(userv2_path, encoding='utf-8')\n",
    "bookv4 = pd.read_csv(bookv4_path, encoding='utf-8')\n",
    "ratings = pd.read_csv(rating_path, encoding='utf-8')\n",
    "\n",
    "merge_ = ratings.merge(bookv4, how='left', on='isbn')\n",
    "data = merge_.merge(usersv2, how='inner', on='user_id')\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data['book_author'] = data['book_author'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())\n",
    "data['publisher'] = data['publisher'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>in a small town in canada clara callan relucta...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>074322678X</td>\n",
       "      <td>4</td>\n",
       "      <td>where you ll find me and other stories</td>\n",
       "      <td>ann beattie</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/074322678X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>now back in print ann beattie 39 s finest shor...</td>\n",
       "      <td>images/074322678X.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0887841740</td>\n",
       "      <td>2</td>\n",
       "      <td>the middle stories</td>\n",
       "      <td>sheila heti</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>harperbusiness</td>\n",
       "      <td>http://images.amazon.com/images/P/0887841740.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0887841740.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1552041778</td>\n",
       "      <td>2</td>\n",
       "      <td>jane doe</td>\n",
       "      <td>r j kaiser</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>firefly books ltd</td>\n",
       "      <td>http://images.amazon.com/images/P/1552041778.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1552041778.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1567407781</td>\n",
       "      <td>6</td>\n",
       "      <td>the witchfinder amos walker mystery series</td>\n",
       "      <td>loren d estleman</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>llewellyn publications</td>\n",
       "      <td>http://images.amazon.com/images/P/1567407781.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1567407781.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        isbn  rating                                  book_title  \\\n",
       "0        8  0002005018       4                                clara callan   \n",
       "1        8  074322678X       4      where you ll find me and other stories   \n",
       "2        8  0887841740       2                          the middle stories   \n",
       "3        8  1552041778       2                                    jane doe   \n",
       "4        8  1567407781       6  the witchfinder amos walker mystery series   \n",
       "\n",
       "            book_author  year_of_publication               publisher  \\\n",
       "0  richard bruce wright               2001.0                 collins   \n",
       "1           ann beattie               2002.0                  pocket   \n",
       "2           sheila heti               2004.0          harperbusiness   \n",
       "3            r j kaiser               1999.0       firefly books ltd   \n",
       "4      loren d estleman               1998.0  llewellyn publications   \n",
       "\n",
       "                                             img_url language  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1  http://images.amazon.com/images/P/074322678X.0...       en   \n",
       "2  http://images.amazon.com/images/P/0887841740.0...       en   \n",
       "3  http://images.amazon.com/images/P/1552041778.0...       en   \n",
       "4  http://images.amazon.com/images/P/1567407781.0...       en   \n",
       "\n",
       "                                             summary  \\\n",
       "0  in a small town in canada clara callan relucta...   \n",
       "1  now back in print ann beattie 39 s finest shor...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                            img_path  category                location   age  \n",
       "0  images/0002005018.01.THUMBZZZ.jpg  fiction1  timmins,ontario,canada  32.0  \n",
       "1  images/074322678X.01.THUMBZZZ.jpg  fiction1  timmins,ontario,canada  32.0  \n",
       "2  images/0887841740.01.THUMBZZZ.jpg  fiction1  timmins,ontario,canada  32.0  \n",
       "3  images/1552041778.01.THUMBZZZ.jpg  fiction1  timmins,ontario,canada  32.0  \n",
       "4  images/1567407781.01.THUMBZZZ.jpg  fiction1  timmins,ontario,canada  32.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 간단한 테스트\n",
    "- category, book_author, publisher, age 만 feature로 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기타 카테고리로 채움 \n",
    "data['category'].fillna('etc', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 피처 선택과 타겟 선택 \n",
    "X_cat = data['category']\n",
    "X_author = data['book_author']\n",
    "X_publisher = data['publisher']\n",
    "X_age = data['age']\n",
    "y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 인코딩\n",
    "le_cat = LabelEncoder()\n",
    "le_author = LabelEncoder()\n",
    "le_publisher = LabelEncoder()\n",
    "X_cat = le_cat.fit_transform(X_cat)\n",
    "X_author = le_author.fit_transform(X_author)\n",
    "X_publisher = le_publisher.fit_transform(X_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age는 vectorize\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_age = vectorizer.fit_transform(X_age.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat 후 X로 넘기기\n",
    "X = pd.concat([pd.Series(X_cat), pd.Series(X_author), pd.Series(X_publisher), pd.DataFrame(X_age.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2], dtype='int64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복되는 column 확인 \n",
    "X.columns[X.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 column 을 unique하게 설정 \n",
    "new_columns = []\n",
    "for i, col in enumerate(X.columns):\n",
    "    if X.columns.duplicated()[i]:\n",
    "        new_columns.append(f\"{col}_{i}\")\n",
    "    else:\n",
    "        new_columns.append(col)\n",
    "X.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test dataset 나누기 \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost 모델 학습 및 기본 파라미터 설정 \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "param = {                                       # 파라미터 설정\n",
    "    'max_depth': 10,                            # 트리의 최대 깊이\n",
    "    'eta': 0.4,                                 # 학습률\n",
    "    'objective': 'reg:squarederror',            # 회귀 문제인 경우 reg:squarederror 사용\n",
    "}\n",
    "num_round = 100                                 # 트리 개수\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.389406015593661\n"
     ]
    }
   ],
   "source": [
    "# 위 파라미터로 설정 시 RMSE 확인 \n",
    "preds = bst.predict(dtest)\n",
    "rmse = ((preds - y_test) ** 2).mean() ** 0.5\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:4.61843\n",
      "[1]\tTest-rmse:3.37601\n",
      "[2]\tTest-rmse:2.79667\n",
      "[3]\tTest-rmse:2.55763\n",
      "[4]\tTest-rmse:2.46010\n",
      "[5]\tTest-rmse:2.42671\n",
      "[6]\tTest-rmse:2.41415\n",
      "[7]\tTest-rmse:2.40965\n",
      "[8]\tTest-rmse:2.40665\n",
      "[9]\tTest-rmse:2.40469\n",
      "[10]\tTest-rmse:2.40283\n",
      "[11]\tTest-rmse:2.40273\n",
      "[12]\tTest-rmse:2.40280\n",
      "[13]\tTest-rmse:2.40254\n",
      "[14]\tTest-rmse:2.40231\n",
      "[15]\tTest-rmse:2.40228\n",
      "[16]\tTest-rmse:2.39945\n",
      "[17]\tTest-rmse:2.39952\n",
      "[18]\tTest-rmse:2.39968\n",
      "[19]\tTest-rmse:2.39958\n",
      "[20]\tTest-rmse:2.39925\n",
      "[21]\tTest-rmse:2.39919\n",
      "[22]\tTest-rmse:2.39845\n",
      "[23]\tTest-rmse:2.39829\n",
      "[24]\tTest-rmse:2.39698\n",
      "[25]\tTest-rmse:2.39698\n",
      "[26]\tTest-rmse:2.39660\n",
      "[27]\tTest-rmse:2.39674\n",
      "[28]\tTest-rmse:2.39677\n",
      "[29]\tTest-rmse:2.39596\n",
      "[30]\tTest-rmse:2.39539\n",
      "[31]\tTest-rmse:2.39479\n",
      "[32]\tTest-rmse:2.39482\n",
      "[33]\tTest-rmse:2.39401\n",
      "[34]\tTest-rmse:2.39387\n",
      "[35]\tTest-rmse:2.39344\n",
      "[36]\tTest-rmse:2.39334\n",
      "[37]\tTest-rmse:2.39322\n",
      "[38]\tTest-rmse:2.39329\n",
      "[39]\tTest-rmse:2.39334\n",
      "[40]\tTest-rmse:2.39281\n",
      "[41]\tTest-rmse:2.39221\n",
      "[42]\tTest-rmse:2.39220\n",
      "[43]\tTest-rmse:2.39158\n",
      "[44]\tTest-rmse:2.39180\n",
      "[45]\tTest-rmse:2.39198\n",
      "[46]\tTest-rmse:2.39203\n",
      "[47]\tTest-rmse:2.39168\n",
      "[48]\tTest-rmse:2.39171\n",
      "[49]\tTest-rmse:2.39175\n",
      "[50]\tTest-rmse:2.39143\n",
      "[51]\tTest-rmse:2.39140\n",
      "[52]\tTest-rmse:2.39157\n",
      "[53]\tTest-rmse:2.39137\n",
      "[54]\tTest-rmse:2.39116\n",
      "[55]\tTest-rmse:2.39132\n",
      "[56]\tTest-rmse:2.39174\n",
      "[57]\tTest-rmse:2.39134\n",
      "[58]\tTest-rmse:2.39144\n",
      "[59]\tTest-rmse:2.39133\n",
      "[60]\tTest-rmse:2.39120\n",
      "[61]\tTest-rmse:2.39164\n",
      "[62]\tTest-rmse:2.39164\n",
      "[63]\tTest-rmse:2.39169\n"
     ]
    }
   ],
   "source": [
    "# num_boost_round 설정 후 best model 저장 \n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "param = {\n",
    "    'max_depth': 10, \n",
    "    'eta': 0.4,\n",
    "    'objective': 'reg:squarederror',\n",
    "}\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.39 with 55 rounds\n"
     ]
    }
   ],
   "source": [
    "# best RMSE 의 rounds 확인 \n",
    "print(\"Best RMSE: {:.2f} with {} rounds\".format(\n",
    "                 bst.best_score,\n",
    "                 bst.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.627793</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>4.628926</td>\n",
       "      <td>0.004887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.380854</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>3.384252</td>\n",
       "      <td>0.005551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.794511</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>2.802341</td>\n",
       "      <td>0.007884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.547568</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>2.559324</td>\n",
       "      <td>0.008233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.448483</td>\n",
       "      <td>0.003820</td>\n",
       "      <td>2.464010</td>\n",
       "      <td>0.009607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.410624</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>2.428613</td>\n",
       "      <td>0.009741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.393455</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>2.415037</td>\n",
       "      <td>0.009735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.384015</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>2.409734</td>\n",
       "      <td>0.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.378465</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>2.407210</td>\n",
       "      <td>0.011413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.375259</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>2.406123</td>\n",
       "      <td>0.011730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.371686</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>2.405382</td>\n",
       "      <td>0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.367610</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>2.403836</td>\n",
       "      <td>0.011661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.363688</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>2.403107</td>\n",
       "      <td>0.011024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.359136</td>\n",
       "      <td>0.003278</td>\n",
       "      <td>2.401809</td>\n",
       "      <td>0.011362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.355316</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>2.401495</td>\n",
       "      <td>0.011425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.352672</td>\n",
       "      <td>0.003834</td>\n",
       "      <td>2.401247</td>\n",
       "      <td>0.011389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.349090</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>2.400521</td>\n",
       "      <td>0.011077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.345160</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>2.399681</td>\n",
       "      <td>0.010953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.343068</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>2.399734</td>\n",
       "      <td>0.010996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.340849</td>\n",
       "      <td>0.003544</td>\n",
       "      <td>2.399558</td>\n",
       "      <td>0.010977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.338468</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>2.399218</td>\n",
       "      <td>0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.336177</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>2.399012</td>\n",
       "      <td>0.011272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.332886</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>2.398538</td>\n",
       "      <td>0.010967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.330800</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>2.398539</td>\n",
       "      <td>0.010976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.328755</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>2.398432</td>\n",
       "      <td>0.011119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.326958</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>2.398432</td>\n",
       "      <td>0.011170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.323956</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>2.398134</td>\n",
       "      <td>0.011188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.321046</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>2.397728</td>\n",
       "      <td>0.011195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.318112</td>\n",
       "      <td>0.005086</td>\n",
       "      <td>2.397333</td>\n",
       "      <td>0.011087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.315732</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>2.397304</td>\n",
       "      <td>0.011254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2.313787</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>2.397118</td>\n",
       "      <td>0.011049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0          4.627793        0.001134        4.628926       0.004887\n",
       "1          3.380854        0.001983        3.384252       0.005551\n",
       "2          2.794511        0.001792        2.802341       0.007884\n",
       "3          2.547568        0.004111        2.559324       0.008233\n",
       "4          2.448483        0.003820        2.464010       0.009607\n",
       "5          2.410624        0.003532        2.428613       0.009741\n",
       "6          2.393455        0.003321        2.415037       0.009735\n",
       "7          2.384015        0.003802        2.409734       0.010582\n",
       "8          2.378465        0.002448        2.407210       0.011413\n",
       "9          2.375259        0.002824        2.406123       0.011730\n",
       "10         2.371686        0.002792        2.405382       0.011861\n",
       "11         2.367610        0.001883        2.403836       0.011661\n",
       "12         2.363688        0.002301        2.403107       0.011024\n",
       "13         2.359136        0.003278        2.401809       0.011362\n",
       "14         2.355316        0.004221        2.401495       0.011425\n",
       "15         2.352672        0.003834        2.401247       0.011389\n",
       "16         2.349090        0.003652        2.400521       0.011077\n",
       "17         2.345160        0.003672        2.399681       0.010953\n",
       "18         2.343068        0.004019        2.399734       0.010996\n",
       "19         2.340849        0.003544        2.399558       0.010977\n",
       "20         2.338468        0.003173        2.399218       0.011239\n",
       "21         2.336177        0.003328        2.399012       0.011272\n",
       "22         2.332886        0.003400        2.398538       0.010967\n",
       "23         2.330800        0.003675        2.398539       0.010976\n",
       "24         2.328755        0.003260        2.398432       0.011119\n",
       "25         2.326958        0.003609        2.398432       0.011170\n",
       "26         2.323956        0.004152        2.398134       0.011188\n",
       "27         2.321046        0.005310        2.397728       0.011195\n",
       "28         2.318112        0.005086        2.397333       0.011087\n",
       "29         2.315732        0.004962        2.397304       0.011254\n",
       "30         2.313787        0.005223        2.397118       0.011049"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation \n",
    "cv_results = xgb.cv( \n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=999, \n",
    "    seed=42, \n",
    "    nfold=5, \n",
    "    metrics={'rmse'}, \n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.397117829900066"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation 결과 확인 \n",
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth, min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하아퍼 파라미터 grid search 수행 \n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 파라미터 설정 \n",
    "param = {\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.3,\n",
    "    'objective': 'reg:squarederror', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tRMSE 2.3909665950694583 for 103 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tRMSE 2.3909543619489884 for 104 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tRMSE 2.3909585006885523 for 89 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tRMSE 2.3912565038170017 for 96 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tRMSE 2.3908701617133876 for 73 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tRMSE 2.3898018431797765 for 95 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tRMSE 2.391966742751217 for 67 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tRMSE 2.390831684064169 for 71 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tRMSE 2.3914210533135587 for 72 rounds\n",
      "Best params: 10, 7, RMSE: 2.3898018431797765\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    # 파라미터 업데이트 \n",
    "    param['max_depth'] = max_depth\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    # Cross validation \n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # best RMSE에 대해 파라미터 업데이트 \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 결과로 max_depth, min_child_weight 설정 \n",
    "param['max_depth'] = 10\n",
    "param['min_child_weight'] = 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsampling, Colsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampling, colsampling grid search 정의 \n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tRMSE 2.3898018431797765 for 95 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tRMSE 2.3913196958983347 for 119 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tRMSE 2.3905695508774256 for 76 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tRMSE 2.389008337944726 for 111 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tRMSE 2.3913417759826623 for 92 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tRMSE 2.3913535744288033 for 92 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tRMSE 2.3900899859381726 for 90 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tRMSE 2.3888946411354928 for 83 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tRMSE 2.3923349221431005 for 71 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tRMSE 2.3918959684289938 for 84 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tRMSE 2.3922983963566846 for 71 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tRMSE 2.3915865734197483 for 80 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tRMSE 2.395132599930482 for 67 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tRMSE 2.3942839504260016 for 66 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tRMSE 2.393469793246056 for 64 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tRMSE 2.3924025881246487 for 76 rounds\n",
      "Best params: 0.9, 0.7, RMSE: 2.3888946411354928\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "# 큰 값 -> 작은 값으로 최적의 파라미터 탐색 \n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    # 파라미터 업데이트 \n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample\n",
    "    # Cross validation\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # best score 업데이트  \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 결과를 통해 최적의 subsample, colsample 찾음\n",
    "param['subsample'] = 0.9\n",
    "param['colsample_bytree'] = 0.7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    # 파라미터 업데이트\n",
    "    param['eta'] = eta\n",
    "    # cross validation \n",
    "    %time cv_results = xgb.cv(param,dtrain,num_boost_round=999,seed=42,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "    # best score 업데이트 \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위 결과를 통해 best eta 설정\n",
    "param['eta'] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'eta': 0.05,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'min_child_weight': 7,\n",
       " 'subsample': 0.9,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 Param 확인 \n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:6.68867\n",
      "[1]\tTest-rmse:6.39872\n",
      "[2]\tTest-rmse:6.12505\n",
      "[3]\tTest-rmse:5.86729\n",
      "[4]\tTest-rmse:5.62437\n",
      "[5]\tTest-rmse:5.39572\n",
      "[6]\tTest-rmse:5.18068\n",
      "[7]\tTest-rmse:4.97858\n",
      "[8]\tTest-rmse:4.78880\n",
      "[9]\tTest-rmse:4.61124\n",
      "[10]\tTest-rmse:4.44461\n",
      "[11]\tTest-rmse:4.28877\n",
      "[12]\tTest-rmse:4.14299\n",
      "[13]\tTest-rmse:4.00706\n",
      "[14]\tTest-rmse:3.88026\n",
      "[15]\tTest-rmse:3.76231\n",
      "[16]\tTest-rmse:3.65256\n",
      "[17]\tTest-rmse:3.55008\n",
      "[18]\tTest-rmse:3.45529\n",
      "[19]\tTest-rmse:3.36711\n",
      "[20]\tTest-rmse:3.28592\n",
      "[21]\tTest-rmse:3.21086\n",
      "[22]\tTest-rmse:3.14132\n",
      "[23]\tTest-rmse:3.07732\n",
      "[24]\tTest-rmse:3.01854\n",
      "[25]\tTest-rmse:2.96462\n",
      "[26]\tTest-rmse:2.91491\n",
      "[27]\tTest-rmse:2.86908\n",
      "[28]\tTest-rmse:2.82737\n",
      "[29]\tTest-rmse:2.78916\n",
      "[30]\tTest-rmse:2.75431\n",
      "[31]\tTest-rmse:2.72246\n",
      "[32]\tTest-rmse:2.69341\n",
      "[33]\tTest-rmse:2.66690\n",
      "[34]\tTest-rmse:2.64264\n",
      "[35]\tTest-rmse:2.62063\n",
      "[36]\tTest-rmse:2.60057\n",
      "[37]\tTest-rmse:2.58226\n",
      "[38]\tTest-rmse:2.56581\n",
      "[39]\tTest-rmse:2.55085\n",
      "[40]\tTest-rmse:2.53714\n",
      "[41]\tTest-rmse:2.52480\n",
      "[42]\tTest-rmse:2.51373\n",
      "[43]\tTest-rmse:2.50363\n",
      "[44]\tTest-rmse:2.49450\n",
      "[45]\tTest-rmse:2.48623\n",
      "[46]\tTest-rmse:2.47857\n",
      "[47]\tTest-rmse:2.47131\n",
      "[48]\tTest-rmse:2.46515\n",
      "[49]\tTest-rmse:2.45913\n",
      "[50]\tTest-rmse:2.45398\n",
      "[51]\tTest-rmse:2.44935\n",
      "[52]\tTest-rmse:2.44517\n",
      "[53]\tTest-rmse:2.44139\n",
      "[54]\tTest-rmse:2.43811\n",
      "[55]\tTest-rmse:2.43510\n",
      "[56]\tTest-rmse:2.43216\n",
      "[57]\tTest-rmse:2.42948\n",
      "[58]\tTest-rmse:2.42680\n",
      "[59]\tTest-rmse:2.42441\n",
      "[60]\tTest-rmse:2.42260\n",
      "[61]\tTest-rmse:2.42096\n",
      "[62]\tTest-rmse:2.41946\n",
      "[63]\tTest-rmse:2.41778\n",
      "[64]\tTest-rmse:2.41652\n",
      "[65]\tTest-rmse:2.41534\n",
      "[66]\tTest-rmse:2.41423\n",
      "[67]\tTest-rmse:2.41327\n",
      "[68]\tTest-rmse:2.41218\n",
      "[69]\tTest-rmse:2.41142\n",
      "[70]\tTest-rmse:2.41059\n",
      "[71]\tTest-rmse:2.40998\n",
      "[72]\tTest-rmse:2.40910\n",
      "[73]\tTest-rmse:2.40852\n",
      "[74]\tTest-rmse:2.40794\n",
      "[75]\tTest-rmse:2.40751\n",
      "[76]\tTest-rmse:2.40702\n",
      "[77]\tTest-rmse:2.40643\n",
      "[78]\tTest-rmse:2.40598\n",
      "[79]\tTest-rmse:2.40560\n",
      "[80]\tTest-rmse:2.40534\n",
      "[81]\tTest-rmse:2.40516\n",
      "[82]\tTest-rmse:2.40491\n",
      "[83]\tTest-rmse:2.40468\n",
      "[84]\tTest-rmse:2.40421\n",
      "[85]\tTest-rmse:2.40375\n",
      "[86]\tTest-rmse:2.40356\n",
      "[87]\tTest-rmse:2.40330\n",
      "[88]\tTest-rmse:2.40304\n",
      "[89]\tTest-rmse:2.40290\n",
      "[90]\tTest-rmse:2.40279\n",
      "[91]\tTest-rmse:2.40267\n",
      "[92]\tTest-rmse:2.40239\n",
      "[93]\tTest-rmse:2.40213\n",
      "[94]\tTest-rmse:2.40176\n",
      "[95]\tTest-rmse:2.40169\n",
      "[96]\tTest-rmse:2.40156\n",
      "[97]\tTest-rmse:2.40147\n",
      "[98]\tTest-rmse:2.40110\n",
      "[99]\tTest-rmse:2.40098\n",
      "[100]\tTest-rmse:2.40096\n",
      "[101]\tTest-rmse:2.40088\n",
      "[102]\tTest-rmse:2.40067\n",
      "[103]\tTest-rmse:2.40061\n",
      "[104]\tTest-rmse:2.40055\n",
      "[105]\tTest-rmse:2.40043\n",
      "[106]\tTest-rmse:2.40032\n",
      "[107]\tTest-rmse:2.40023\n",
      "[108]\tTest-rmse:2.40013\n",
      "[109]\tTest-rmse:2.39973\n",
      "[110]\tTest-rmse:2.39953\n",
      "[111]\tTest-rmse:2.39944\n",
      "[112]\tTest-rmse:2.39899\n",
      "[113]\tTest-rmse:2.39892\n",
      "[114]\tTest-rmse:2.39882\n",
      "[115]\tTest-rmse:2.39881\n",
      "[116]\tTest-rmse:2.39873\n",
      "[117]\tTest-rmse:2.39869\n",
      "[118]\tTest-rmse:2.39840\n",
      "[119]\tTest-rmse:2.39832\n",
      "[120]\tTest-rmse:2.39830\n",
      "[121]\tTest-rmse:2.39827\n",
      "[122]\tTest-rmse:2.39825\n",
      "[123]\tTest-rmse:2.39824\n",
      "[124]\tTest-rmse:2.39818\n",
      "[125]\tTest-rmse:2.39809\n",
      "[126]\tTest-rmse:2.39806\n",
      "[127]\tTest-rmse:2.39796\n",
      "[128]\tTest-rmse:2.39789\n",
      "[129]\tTest-rmse:2.39785\n",
      "[130]\tTest-rmse:2.39782\n",
      "[131]\tTest-rmse:2.39783\n",
      "[132]\tTest-rmse:2.39763\n",
      "[133]\tTest-rmse:2.39749\n",
      "[134]\tTest-rmse:2.39714\n",
      "[135]\tTest-rmse:2.39709\n",
      "[136]\tTest-rmse:2.39704\n",
      "[137]\tTest-rmse:2.39688\n",
      "[138]\tTest-rmse:2.39683\n",
      "[139]\tTest-rmse:2.39679\n",
      "[140]\tTest-rmse:2.39677\n",
      "[141]\tTest-rmse:2.39675\n",
      "[142]\tTest-rmse:2.39670\n",
      "[143]\tTest-rmse:2.39659\n",
      "[144]\tTest-rmse:2.39642\n",
      "[145]\tTest-rmse:2.39633\n",
      "[146]\tTest-rmse:2.39630\n",
      "[147]\tTest-rmse:2.39608\n",
      "[148]\tTest-rmse:2.39603\n",
      "[149]\tTest-rmse:2.39602\n",
      "[150]\tTest-rmse:2.39594\n",
      "[151]\tTest-rmse:2.39585\n",
      "[152]\tTest-rmse:2.39585\n",
      "[153]\tTest-rmse:2.39582\n",
      "[154]\tTest-rmse:2.39569\n",
      "[155]\tTest-rmse:2.39566\n",
      "[156]\tTest-rmse:2.39545\n",
      "[157]\tTest-rmse:2.39539\n",
      "[158]\tTest-rmse:2.39533\n",
      "[159]\tTest-rmse:2.39514\n",
      "[160]\tTest-rmse:2.39478\n",
      "[161]\tTest-rmse:2.39459\n",
      "[162]\tTest-rmse:2.39450\n",
      "[163]\tTest-rmse:2.39449\n",
      "[164]\tTest-rmse:2.39440\n",
      "[165]\tTest-rmse:2.39436\n",
      "[166]\tTest-rmse:2.39435\n",
      "[167]\tTest-rmse:2.39423\n",
      "[168]\tTest-rmse:2.39394\n",
      "[169]\tTest-rmse:2.39392\n",
      "[170]\tTest-rmse:2.39389\n",
      "[171]\tTest-rmse:2.39373\n",
      "[172]\tTest-rmse:2.39351\n",
      "[173]\tTest-rmse:2.39323\n",
      "[174]\tTest-rmse:2.39311\n",
      "[175]\tTest-rmse:2.39305\n",
      "[176]\tTest-rmse:2.39286\n",
      "[177]\tTest-rmse:2.39262\n",
      "[178]\tTest-rmse:2.39253\n",
      "[179]\tTest-rmse:2.39253\n",
      "[180]\tTest-rmse:2.39243\n",
      "[181]\tTest-rmse:2.39239\n",
      "[182]\tTest-rmse:2.39228\n",
      "[183]\tTest-rmse:2.39212\n",
      "[184]\tTest-rmse:2.39198\n",
      "[185]\tTest-rmse:2.39191\n",
      "[186]\tTest-rmse:2.39174\n",
      "[187]\tTest-rmse:2.39168\n",
      "[188]\tTest-rmse:2.39169\n",
      "[189]\tTest-rmse:2.39163\n",
      "[190]\tTest-rmse:2.39142\n",
      "[191]\tTest-rmse:2.39135\n",
      "[192]\tTest-rmse:2.39125\n",
      "[193]\tTest-rmse:2.39108\n",
      "[194]\tTest-rmse:2.39099\n",
      "[195]\tTest-rmse:2.39080\n",
      "[196]\tTest-rmse:2.39080\n",
      "[197]\tTest-rmse:2.39077\n",
      "[198]\tTest-rmse:2.39071\n",
      "[199]\tTest-rmse:2.39070\n",
      "[200]\tTest-rmse:2.39065\n",
      "[201]\tTest-rmse:2.39056\n",
      "[202]\tTest-rmse:2.39049\n",
      "[203]\tTest-rmse:2.39033\n",
      "[204]\tTest-rmse:2.39032\n",
      "[205]\tTest-rmse:2.39024\n",
      "[206]\tTest-rmse:2.39012\n",
      "[207]\tTest-rmse:2.39002\n",
      "[208]\tTest-rmse:2.39002\n",
      "[209]\tTest-rmse:2.38996\n",
      "[210]\tTest-rmse:2.38995\n",
      "[211]\tTest-rmse:2.38994\n",
      "[212]\tTest-rmse:2.38996\n",
      "[213]\tTest-rmse:2.38996\n",
      "[214]\tTest-rmse:2.38981\n",
      "[215]\tTest-rmse:2.38969\n",
      "[216]\tTest-rmse:2.38969\n",
      "[217]\tTest-rmse:2.38961\n",
      "[218]\tTest-rmse:2.38961\n",
      "[219]\tTest-rmse:2.38956\n",
      "[220]\tTest-rmse:2.38949\n",
      "[221]\tTest-rmse:2.38948\n",
      "[222]\tTest-rmse:2.38944\n",
      "[223]\tTest-rmse:2.38945\n",
      "[224]\tTest-rmse:2.38943\n",
      "[225]\tTest-rmse:2.38944\n",
      "[226]\tTest-rmse:2.38939\n",
      "[227]\tTest-rmse:2.38927\n",
      "[228]\tTest-rmse:2.38921\n",
      "[229]\tTest-rmse:2.38918\n",
      "[230]\tTest-rmse:2.38914\n",
      "[231]\tTest-rmse:2.38914\n",
      "[232]\tTest-rmse:2.38915\n",
      "[233]\tTest-rmse:2.38897\n",
      "[234]\tTest-rmse:2.38897\n",
      "[235]\tTest-rmse:2.38887\n",
      "[236]\tTest-rmse:2.38872\n",
      "[237]\tTest-rmse:2.38854\n",
      "[238]\tTest-rmse:2.38840\n",
      "[239]\tTest-rmse:2.38831\n",
      "[240]\tTest-rmse:2.38826\n",
      "[241]\tTest-rmse:2.38822\n",
      "[242]\tTest-rmse:2.38822\n",
      "[243]\tTest-rmse:2.38825\n",
      "[244]\tTest-rmse:2.38825\n",
      "[245]\tTest-rmse:2.38817\n",
      "[246]\tTest-rmse:2.38820\n",
      "[247]\tTest-rmse:2.38806\n",
      "[248]\tTest-rmse:2.38801\n",
      "[249]\tTest-rmse:2.38796\n",
      "[250]\tTest-rmse:2.38790\n",
      "[251]\tTest-rmse:2.38784\n",
      "[252]\tTest-rmse:2.38784\n",
      "[253]\tTest-rmse:2.38769\n",
      "[254]\tTest-rmse:2.38768\n",
      "[255]\tTest-rmse:2.38763\n",
      "[256]\tTest-rmse:2.38759\n",
      "[257]\tTest-rmse:2.38761\n",
      "[258]\tTest-rmse:2.38757\n",
      "[259]\tTest-rmse:2.38750\n",
      "[260]\tTest-rmse:2.38740\n",
      "[261]\tTest-rmse:2.38739\n",
      "[262]\tTest-rmse:2.38724\n",
      "[263]\tTest-rmse:2.38721\n",
      "[264]\tTest-rmse:2.38722\n",
      "[265]\tTest-rmse:2.38713\n",
      "[266]\tTest-rmse:2.38711\n",
      "[267]\tTest-rmse:2.38700\n",
      "[268]\tTest-rmse:2.38697\n",
      "[269]\tTest-rmse:2.38685\n",
      "[270]\tTest-rmse:2.38678\n",
      "[271]\tTest-rmse:2.38676\n",
      "[272]\tTest-rmse:2.38664\n",
      "[273]\tTest-rmse:2.38665\n",
      "[274]\tTest-rmse:2.38665\n",
      "[275]\tTest-rmse:2.38645\n",
      "[276]\tTest-rmse:2.38638\n",
      "[277]\tTest-rmse:2.38629\n",
      "[278]\tTest-rmse:2.38616\n",
      "[279]\tTest-rmse:2.38608\n",
      "[280]\tTest-rmse:2.38596\n",
      "[281]\tTest-rmse:2.38599\n",
      "[282]\tTest-rmse:2.38591\n",
      "[283]\tTest-rmse:2.38593\n",
      "[284]\tTest-rmse:2.38595\n",
      "[285]\tTest-rmse:2.38587\n",
      "[286]\tTest-rmse:2.38569\n",
      "[287]\tTest-rmse:2.38556\n",
      "[288]\tTest-rmse:2.38559\n",
      "[289]\tTest-rmse:2.38550\n",
      "[290]\tTest-rmse:2.38551\n",
      "[291]\tTest-rmse:2.38541\n",
      "[292]\tTest-rmse:2.38534\n",
      "[293]\tTest-rmse:2.38535\n",
      "[294]\tTest-rmse:2.38533\n",
      "[295]\tTest-rmse:2.38532\n",
      "[296]\tTest-rmse:2.38531\n",
      "[297]\tTest-rmse:2.38524\n",
      "[298]\tTest-rmse:2.38517\n",
      "[299]\tTest-rmse:2.38516\n",
      "[300]\tTest-rmse:2.38506\n",
      "[301]\tTest-rmse:2.38503\n",
      "[302]\tTest-rmse:2.38497\n",
      "[303]\tTest-rmse:2.38486\n",
      "[304]\tTest-rmse:2.38475\n",
      "[305]\tTest-rmse:2.38457\n",
      "[306]\tTest-rmse:2.38445\n",
      "[307]\tTest-rmse:2.38443\n",
      "[308]\tTest-rmse:2.38441\n",
      "[309]\tTest-rmse:2.38441\n",
      "[310]\tTest-rmse:2.38439\n",
      "[311]\tTest-rmse:2.38438\n",
      "[312]\tTest-rmse:2.38435\n",
      "[313]\tTest-rmse:2.38433\n",
      "[314]\tTest-rmse:2.38433\n",
      "[315]\tTest-rmse:2.38424\n",
      "[316]\tTest-rmse:2.38416\n",
      "[317]\tTest-rmse:2.38410\n",
      "[318]\tTest-rmse:2.38403\n",
      "[319]\tTest-rmse:2.38398\n",
      "[320]\tTest-rmse:2.38389\n",
      "[321]\tTest-rmse:2.38387\n",
      "[322]\tTest-rmse:2.38385\n",
      "[323]\tTest-rmse:2.38383\n",
      "[324]\tTest-rmse:2.38383\n",
      "[325]\tTest-rmse:2.38383\n",
      "[326]\tTest-rmse:2.38381\n",
      "[327]\tTest-rmse:2.38362\n",
      "[328]\tTest-rmse:2.38348\n",
      "[329]\tTest-rmse:2.38344\n",
      "[330]\tTest-rmse:2.38341\n",
      "[331]\tTest-rmse:2.38330\n",
      "[332]\tTest-rmse:2.38325\n",
      "[333]\tTest-rmse:2.38317\n",
      "[334]\tTest-rmse:2.38314\n",
      "[335]\tTest-rmse:2.38308\n",
      "[336]\tTest-rmse:2.38308\n",
      "[337]\tTest-rmse:2.38300\n",
      "[338]\tTest-rmse:2.38294\n",
      "[339]\tTest-rmse:2.38292\n",
      "[340]\tTest-rmse:2.38291\n",
      "[341]\tTest-rmse:2.38287\n",
      "[342]\tTest-rmse:2.38282\n",
      "[343]\tTest-rmse:2.38280\n",
      "[344]\tTest-rmse:2.38276\n",
      "[345]\tTest-rmse:2.38258\n",
      "[346]\tTest-rmse:2.38255\n",
      "[347]\tTest-rmse:2.38253\n",
      "[348]\tTest-rmse:2.38251\n",
      "[349]\tTest-rmse:2.38248\n",
      "[350]\tTest-rmse:2.38243\n",
      "[351]\tTest-rmse:2.38240\n",
      "[352]\tTest-rmse:2.38237\n",
      "[353]\tTest-rmse:2.38228\n",
      "[354]\tTest-rmse:2.38221\n",
      "[355]\tTest-rmse:2.38219\n",
      "[356]\tTest-rmse:2.38212\n",
      "[357]\tTest-rmse:2.38203\n",
      "[358]\tTest-rmse:2.38203\n",
      "[359]\tTest-rmse:2.38195\n",
      "[360]\tTest-rmse:2.38195\n",
      "[361]\tTest-rmse:2.38192\n",
      "[362]\tTest-rmse:2.38188\n",
      "[363]\tTest-rmse:2.38188\n",
      "[364]\tTest-rmse:2.38183\n",
      "[365]\tTest-rmse:2.38181\n",
      "[366]\tTest-rmse:2.38184\n",
      "[367]\tTest-rmse:2.38176\n",
      "[368]\tTest-rmse:2.38161\n",
      "[369]\tTest-rmse:2.38160\n",
      "[370]\tTest-rmse:2.38160\n",
      "[371]\tTest-rmse:2.38160\n",
      "[372]\tTest-rmse:2.38157\n",
      "[373]\tTest-rmse:2.38158\n",
      "[374]\tTest-rmse:2.38155\n",
      "[375]\tTest-rmse:2.38151\n",
      "[376]\tTest-rmse:2.38143\n",
      "[377]\tTest-rmse:2.38142\n",
      "[378]\tTest-rmse:2.38141\n",
      "[379]\tTest-rmse:2.38140\n",
      "[380]\tTest-rmse:2.38142\n",
      "[381]\tTest-rmse:2.38142\n",
      "[382]\tTest-rmse:2.38141\n",
      "[383]\tTest-rmse:2.38141\n",
      "[384]\tTest-rmse:2.38141\n",
      "[385]\tTest-rmse:2.38139\n",
      "[386]\tTest-rmse:2.38138\n",
      "[387]\tTest-rmse:2.38137\n",
      "[388]\tTest-rmse:2.38132\n",
      "[389]\tTest-rmse:2.38132\n",
      "[390]\tTest-rmse:2.38131\n",
      "[391]\tTest-rmse:2.38132\n",
      "[392]\tTest-rmse:2.38131\n",
      "[393]\tTest-rmse:2.38131\n",
      "[394]\tTest-rmse:2.38129\n",
      "[395]\tTest-rmse:2.38123\n",
      "[396]\tTest-rmse:2.38111\n",
      "[397]\tTest-rmse:2.38109\n",
      "[398]\tTest-rmse:2.38104\n",
      "[399]\tTest-rmse:2.38101\n",
      "[400]\tTest-rmse:2.38100\n",
      "[401]\tTest-rmse:2.38095\n",
      "[402]\tTest-rmse:2.38092\n",
      "[403]\tTest-rmse:2.38090\n",
      "[404]\tTest-rmse:2.38087\n",
      "[405]\tTest-rmse:2.38090\n",
      "[406]\tTest-rmse:2.38084\n",
      "[407]\tTest-rmse:2.38078\n",
      "[408]\tTest-rmse:2.38074\n",
      "[409]\tTest-rmse:2.38053\n",
      "[410]\tTest-rmse:2.38048\n",
      "[411]\tTest-rmse:2.38039\n",
      "[412]\tTest-rmse:2.38032\n",
      "[413]\tTest-rmse:2.38022\n",
      "[414]\tTest-rmse:2.38023\n",
      "[415]\tTest-rmse:2.38019\n",
      "[416]\tTest-rmse:2.38020\n",
      "[417]\tTest-rmse:2.38014\n",
      "[418]\tTest-rmse:2.38013\n",
      "[419]\tTest-rmse:2.38013\n",
      "[420]\tTest-rmse:2.38013\n",
      "[421]\tTest-rmse:2.38014\n",
      "[422]\tTest-rmse:2.38013\n",
      "[423]\tTest-rmse:2.38008\n",
      "[424]\tTest-rmse:2.38009\n",
      "[425]\tTest-rmse:2.38002\n",
      "[426]\tTest-rmse:2.37999\n",
      "[427]\tTest-rmse:2.37995\n",
      "[428]\tTest-rmse:2.37994\n",
      "[429]\tTest-rmse:2.37993\n",
      "[430]\tTest-rmse:2.37992\n",
      "[431]\tTest-rmse:2.37983\n",
      "[432]\tTest-rmse:2.37981\n",
      "[433]\tTest-rmse:2.37974\n",
      "[434]\tTest-rmse:2.37975\n",
      "[435]\tTest-rmse:2.37963\n",
      "[436]\tTest-rmse:2.37960\n",
      "[437]\tTest-rmse:2.37953\n",
      "[438]\tTest-rmse:2.37952\n",
      "[439]\tTest-rmse:2.37939\n",
      "[440]\tTest-rmse:2.37930\n",
      "[441]\tTest-rmse:2.37923\n",
      "[442]\tTest-rmse:2.37920\n",
      "[443]\tTest-rmse:2.37923\n",
      "[444]\tTest-rmse:2.37919\n",
      "[445]\tTest-rmse:2.37916\n",
      "[446]\tTest-rmse:2.37914\n",
      "[447]\tTest-rmse:2.37915\n",
      "[448]\tTest-rmse:2.37905\n",
      "[449]\tTest-rmse:2.37899\n",
      "[450]\tTest-rmse:2.37899\n",
      "[451]\tTest-rmse:2.37894\n",
      "[452]\tTest-rmse:2.37885\n",
      "[453]\tTest-rmse:2.37885\n",
      "[454]\tTest-rmse:2.37882\n",
      "[455]\tTest-rmse:2.37880\n",
      "[456]\tTest-rmse:2.37872\n",
      "[457]\tTest-rmse:2.37868\n",
      "[458]\tTest-rmse:2.37863\n",
      "[459]\tTest-rmse:2.37865\n",
      "[460]\tTest-rmse:2.37857\n",
      "[461]\tTest-rmse:2.37857\n",
      "[462]\tTest-rmse:2.37856\n",
      "[463]\tTest-rmse:2.37858\n",
      "[464]\tTest-rmse:2.37853\n",
      "[465]\tTest-rmse:2.37852\n",
      "[466]\tTest-rmse:2.37849\n",
      "[467]\tTest-rmse:2.37850\n",
      "[468]\tTest-rmse:2.37850\n",
      "[469]\tTest-rmse:2.37842\n",
      "[470]\tTest-rmse:2.37840\n",
      "[471]\tTest-rmse:2.37838\n",
      "[472]\tTest-rmse:2.37836\n",
      "[473]\tTest-rmse:2.37835\n",
      "[474]\tTest-rmse:2.37833\n",
      "[475]\tTest-rmse:2.37832\n",
      "[476]\tTest-rmse:2.37834\n",
      "[477]\tTest-rmse:2.37833\n",
      "[478]\tTest-rmse:2.37829\n",
      "[479]\tTest-rmse:2.37826\n",
      "[480]\tTest-rmse:2.37826\n",
      "[481]\tTest-rmse:2.37820\n",
      "[482]\tTest-rmse:2.37812\n",
      "[483]\tTest-rmse:2.37811\n",
      "[484]\tTest-rmse:2.37807\n",
      "[485]\tTest-rmse:2.37807\n",
      "[486]\tTest-rmse:2.37801\n",
      "[487]\tTest-rmse:2.37797\n",
      "[488]\tTest-rmse:2.37797\n",
      "[489]\tTest-rmse:2.37798\n",
      "[490]\tTest-rmse:2.37792\n",
      "[491]\tTest-rmse:2.37791\n",
      "[492]\tTest-rmse:2.37788\n",
      "[493]\tTest-rmse:2.37784\n",
      "[494]\tTest-rmse:2.37783\n",
      "[495]\tTest-rmse:2.37781\n",
      "[496]\tTest-rmse:2.37775\n",
      "[497]\tTest-rmse:2.37770\n",
      "[498]\tTest-rmse:2.37762\n",
      "[499]\tTest-rmse:2.37761\n",
      "[500]\tTest-rmse:2.37756\n",
      "[501]\tTest-rmse:2.37754\n",
      "[502]\tTest-rmse:2.37750\n",
      "[503]\tTest-rmse:2.37747\n",
      "[504]\tTest-rmse:2.37745\n",
      "[505]\tTest-rmse:2.37746\n",
      "[506]\tTest-rmse:2.37746\n",
      "[507]\tTest-rmse:2.37748\n",
      "[508]\tTest-rmse:2.37744\n",
      "[509]\tTest-rmse:2.37745\n",
      "[510]\tTest-rmse:2.37744\n",
      "[511]\tTest-rmse:2.37740\n",
      "[512]\tTest-rmse:2.37739\n",
      "[513]\tTest-rmse:2.37734\n",
      "[514]\tTest-rmse:2.37734\n",
      "[515]\tTest-rmse:2.37730\n",
      "[516]\tTest-rmse:2.37728\n",
      "[517]\tTest-rmse:2.37730\n",
      "[518]\tTest-rmse:2.37727\n",
      "[519]\tTest-rmse:2.37715\n",
      "[520]\tTest-rmse:2.37717\n",
      "[521]\tTest-rmse:2.37718\n",
      "[522]\tTest-rmse:2.37713\n",
      "[523]\tTest-rmse:2.37703\n",
      "[524]\tTest-rmse:2.37695\n",
      "[525]\tTest-rmse:2.37693\n",
      "[526]\tTest-rmse:2.37696\n",
      "[527]\tTest-rmse:2.37695\n",
      "[528]\tTest-rmse:2.37697\n",
      "[529]\tTest-rmse:2.37697\n",
      "[530]\tTest-rmse:2.37694\n",
      "[531]\tTest-rmse:2.37694\n",
      "[532]\tTest-rmse:2.37691\n",
      "[533]\tTest-rmse:2.37681\n",
      "[534]\tTest-rmse:2.37680\n",
      "[535]\tTest-rmse:2.37679\n",
      "[536]\tTest-rmse:2.37680\n",
      "[537]\tTest-rmse:2.37678\n",
      "[538]\tTest-rmse:2.37675\n",
      "[539]\tTest-rmse:2.37673\n",
      "[540]\tTest-rmse:2.37670\n",
      "[541]\tTest-rmse:2.37670\n",
      "[542]\tTest-rmse:2.37666\n",
      "[543]\tTest-rmse:2.37664\n",
      "[544]\tTest-rmse:2.37659\n",
      "[545]\tTest-rmse:2.37659\n",
      "[546]\tTest-rmse:2.37657\n",
      "[547]\tTest-rmse:2.37657\n",
      "[548]\tTest-rmse:2.37650\n",
      "[549]\tTest-rmse:2.37649\n",
      "[550]\tTest-rmse:2.37652\n",
      "[551]\tTest-rmse:2.37649\n",
      "[552]\tTest-rmse:2.37651\n",
      "[553]\tTest-rmse:2.37649\n",
      "[554]\tTest-rmse:2.37649\n",
      "[555]\tTest-rmse:2.37648\n",
      "[556]\tTest-rmse:2.37647\n",
      "[557]\tTest-rmse:2.37646\n",
      "[558]\tTest-rmse:2.37646\n",
      "[559]\tTest-rmse:2.37646\n",
      "[560]\tTest-rmse:2.37647\n",
      "[561]\tTest-rmse:2.37646\n",
      "[562]\tTest-rmse:2.37638\n",
      "[563]\tTest-rmse:2.37638\n",
      "[564]\tTest-rmse:2.37633\n",
      "[565]\tTest-rmse:2.37632\n",
      "[566]\tTest-rmse:2.37630\n",
      "[567]\tTest-rmse:2.37632\n",
      "[568]\tTest-rmse:2.37632\n",
      "[569]\tTest-rmse:2.37633\n",
      "[570]\tTest-rmse:2.37620\n",
      "[571]\tTest-rmse:2.37618\n",
      "[572]\tTest-rmse:2.37618\n",
      "[573]\tTest-rmse:2.37617\n",
      "[574]\tTest-rmse:2.37616\n",
      "[575]\tTest-rmse:2.37611\n",
      "[576]\tTest-rmse:2.37606\n",
      "[577]\tTest-rmse:2.37599\n",
      "[578]\tTest-rmse:2.37596\n",
      "[579]\tTest-rmse:2.37593\n",
      "[580]\tTest-rmse:2.37592\n",
      "[581]\tTest-rmse:2.37590\n",
      "[582]\tTest-rmse:2.37590\n",
      "[583]\tTest-rmse:2.37590\n",
      "[584]\tTest-rmse:2.37589\n",
      "[585]\tTest-rmse:2.37587\n",
      "[586]\tTest-rmse:2.37589\n",
      "[587]\tTest-rmse:2.37589\n",
      "[588]\tTest-rmse:2.37585\n",
      "[589]\tTest-rmse:2.37587\n",
      "[590]\tTest-rmse:2.37584\n",
      "[591]\tTest-rmse:2.37577\n",
      "[592]\tTest-rmse:2.37577\n",
      "[593]\tTest-rmse:2.37577\n",
      "[594]\tTest-rmse:2.37577\n",
      "[595]\tTest-rmse:2.37575\n",
      "[596]\tTest-rmse:2.37576\n",
      "[597]\tTest-rmse:2.37576\n",
      "[598]\tTest-rmse:2.37575\n",
      "[599]\tTest-rmse:2.37575\n",
      "[600]\tTest-rmse:2.37573\n",
      "[601]\tTest-rmse:2.37569\n",
      "[602]\tTest-rmse:2.37567\n",
      "[603]\tTest-rmse:2.37569\n",
      "[604]\tTest-rmse:2.37565\n",
      "[605]\tTest-rmse:2.37560\n",
      "[606]\tTest-rmse:2.37561\n",
      "[607]\tTest-rmse:2.37554\n",
      "[608]\tTest-rmse:2.37549\n",
      "[609]\tTest-rmse:2.37539\n",
      "[610]\tTest-rmse:2.37539\n",
      "[611]\tTest-rmse:2.37536\n",
      "[612]\tTest-rmse:2.37539\n",
      "[613]\tTest-rmse:2.37538\n",
      "[614]\tTest-rmse:2.37541\n",
      "[615]\tTest-rmse:2.37541\n",
      "[616]\tTest-rmse:2.37534\n",
      "[617]\tTest-rmse:2.37534\n",
      "[618]\tTest-rmse:2.37531\n",
      "[619]\tTest-rmse:2.37530\n",
      "[620]\tTest-rmse:2.37531\n",
      "[621]\tTest-rmse:2.37530\n",
      "[622]\tTest-rmse:2.37531\n",
      "[623]\tTest-rmse:2.37524\n",
      "[624]\tTest-rmse:2.37521\n",
      "[625]\tTest-rmse:2.37512\n",
      "[626]\tTest-rmse:2.37508\n",
      "[627]\tTest-rmse:2.37509\n",
      "[628]\tTest-rmse:2.37503\n",
      "[629]\tTest-rmse:2.37501\n",
      "[630]\tTest-rmse:2.37501\n",
      "[631]\tTest-rmse:2.37502\n",
      "[632]\tTest-rmse:2.37500\n",
      "[633]\tTest-rmse:2.37501\n",
      "[634]\tTest-rmse:2.37500\n",
      "[635]\tTest-rmse:2.37497\n",
      "[636]\tTest-rmse:2.37493\n",
      "[637]\tTest-rmse:2.37489\n",
      "[638]\tTest-rmse:2.37480\n",
      "[639]\tTest-rmse:2.37481\n",
      "[640]\tTest-rmse:2.37480\n",
      "[641]\tTest-rmse:2.37482\n",
      "[642]\tTest-rmse:2.37482\n",
      "[643]\tTest-rmse:2.37481\n",
      "[644]\tTest-rmse:2.37481\n",
      "[645]\tTest-rmse:2.37481\n",
      "[646]\tTest-rmse:2.37481\n",
      "[647]\tTest-rmse:2.37480\n",
      "[648]\tTest-rmse:2.37477\n",
      "[649]\tTest-rmse:2.37477\n",
      "[650]\tTest-rmse:2.37478\n",
      "[651]\tTest-rmse:2.37479\n",
      "[652]\tTest-rmse:2.37477\n",
      "[653]\tTest-rmse:2.37476\n",
      "[654]\tTest-rmse:2.37475\n",
      "[655]\tTest-rmse:2.37472\n",
      "[656]\tTest-rmse:2.37470\n",
      "[657]\tTest-rmse:2.37472\n",
      "[658]\tTest-rmse:2.37468\n",
      "[659]\tTest-rmse:2.37464\n",
      "[660]\tTest-rmse:2.37461\n",
      "[661]\tTest-rmse:2.37461\n",
      "[662]\tTest-rmse:2.37461\n",
      "[663]\tTest-rmse:2.37462\n",
      "[664]\tTest-rmse:2.37460\n",
      "[665]\tTest-rmse:2.37461\n",
      "[666]\tTest-rmse:2.37461\n",
      "[667]\tTest-rmse:2.37459\n",
      "[668]\tTest-rmse:2.37460\n",
      "[669]\tTest-rmse:2.37459\n",
      "[670]\tTest-rmse:2.37455\n",
      "[671]\tTest-rmse:2.37453\n",
      "[672]\tTest-rmse:2.37451\n",
      "[673]\tTest-rmse:2.37448\n",
      "[674]\tTest-rmse:2.37448\n",
      "[675]\tTest-rmse:2.37448\n",
      "[676]\tTest-rmse:2.37448\n",
      "[677]\tTest-rmse:2.37447\n",
      "[678]\tTest-rmse:2.37446\n",
      "[679]\tTest-rmse:2.37443\n",
      "[680]\tTest-rmse:2.37443\n",
      "[681]\tTest-rmse:2.37442\n",
      "[682]\tTest-rmse:2.37442\n",
      "[683]\tTest-rmse:2.37439\n",
      "[684]\tTest-rmse:2.37439\n",
      "[685]\tTest-rmse:2.37440\n",
      "[686]\tTest-rmse:2.37435\n",
      "[687]\tTest-rmse:2.37438\n",
      "[688]\tTest-rmse:2.37437\n",
      "[689]\tTest-rmse:2.37433\n",
      "[690]\tTest-rmse:2.37434\n",
      "[691]\tTest-rmse:2.37433\n",
      "[692]\tTest-rmse:2.37432\n",
      "[693]\tTest-rmse:2.37435\n",
      "[694]\tTest-rmse:2.37435\n",
      "[695]\tTest-rmse:2.37431\n",
      "[696]\tTest-rmse:2.37428\n",
      "[697]\tTest-rmse:2.37430\n",
      "[698]\tTest-rmse:2.37430\n",
      "[699]\tTest-rmse:2.37430\n",
      "[700]\tTest-rmse:2.37427\n",
      "[701]\tTest-rmse:2.37427\n",
      "[702]\tTest-rmse:2.37426\n",
      "[703]\tTest-rmse:2.37423\n",
      "[704]\tTest-rmse:2.37421\n",
      "[705]\tTest-rmse:2.37419\n",
      "[706]\tTest-rmse:2.37415\n",
      "[707]\tTest-rmse:2.37411\n",
      "[708]\tTest-rmse:2.37411\n",
      "[709]\tTest-rmse:2.37407\n",
      "[710]\tTest-rmse:2.37403\n",
      "[711]\tTest-rmse:2.37403\n",
      "[712]\tTest-rmse:2.37402\n",
      "[713]\tTest-rmse:2.37402\n",
      "[714]\tTest-rmse:2.37396\n",
      "[715]\tTest-rmse:2.37398\n",
      "[716]\tTest-rmse:2.37398\n",
      "[717]\tTest-rmse:2.37394\n",
      "[718]\tTest-rmse:2.37397\n",
      "[719]\tTest-rmse:2.37397\n",
      "[720]\tTest-rmse:2.37392\n",
      "[721]\tTest-rmse:2.37388\n",
      "[722]\tTest-rmse:2.37388\n",
      "[723]\tTest-rmse:2.37389\n",
      "[724]\tTest-rmse:2.37389\n",
      "[725]\tTest-rmse:2.37390\n",
      "[726]\tTest-rmse:2.37388\n",
      "[727]\tTest-rmse:2.37386\n",
      "[728]\tTest-rmse:2.37384\n",
      "[729]\tTest-rmse:2.37380\n",
      "[730]\tTest-rmse:2.37381\n",
      "[731]\tTest-rmse:2.37379\n",
      "[732]\tTest-rmse:2.37373\n",
      "[733]\tTest-rmse:2.37376\n",
      "[734]\tTest-rmse:2.37373\n",
      "[735]\tTest-rmse:2.37373\n",
      "[736]\tTest-rmse:2.37370\n",
      "[737]\tTest-rmse:2.37372\n",
      "[738]\tTest-rmse:2.37366\n",
      "[739]\tTest-rmse:2.37367\n",
      "[740]\tTest-rmse:2.37368\n",
      "[741]\tTest-rmse:2.37368\n",
      "[742]\tTest-rmse:2.37369\n",
      "[743]\tTest-rmse:2.37369\n",
      "[744]\tTest-rmse:2.37369\n",
      "[745]\tTest-rmse:2.37365\n",
      "[746]\tTest-rmse:2.37365\n",
      "[747]\tTest-rmse:2.37363\n",
      "[748]\tTest-rmse:2.37362\n",
      "[749]\tTest-rmse:2.37363\n",
      "[750]\tTest-rmse:2.37362\n",
      "[751]\tTest-rmse:2.37364\n",
      "[752]\tTest-rmse:2.37365\n",
      "[753]\tTest-rmse:2.37365\n",
      "[754]\tTest-rmse:2.37367\n",
      "[755]\tTest-rmse:2.37368\n",
      "[756]\tTest-rmse:2.37370\n",
      "[757]\tTest-rmse:2.37368\n"
     ]
    }
   ],
   "source": [
    "# 최종 Test\n",
    "model = xgb.train(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.37 in 749 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 주의님 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 149570 entries, 0 to 149569\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   isbn                 149570 non-null  object \n",
      " 1   book_title           149570 non-null  object \n",
      " 2   book_author          149570 non-null  object \n",
      " 3   year_of_publication  149570 non-null  float64\n",
      " 4   publisher            149570 non-null  object \n",
      " 5   img_url              149570 non-null  object \n",
      " 6   language             149570 non-null  object \n",
      " 7   summary              82340 non-null   object \n",
      " 8   img_path             149570 non-null  object \n",
      " 9   category             148582 non-null  object \n",
      " 10  summary_topic        82343 non-null   float64\n",
      " 11  category_topic       80719 non-null   float64\n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 14.8+ MB\n"
     ]
    }
   ],
   "source": [
    "topic_path = os.path.join(base_path, 'books_topic_modeling_v2.csv')\n",
    "topic_book = pd.read_csv(topic_path, encoding='utf-8')\n",
    "\n",
    "# books 합치기 \n",
    "topic_book = topic_book[['isbn', 'summary_topic', 'category_topic']]\n",
    "merge_book = bookv4.merge(topic_book, how='left', on='isbn')\n",
    "merge_book.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                   149570\n",
       "book_title             132713\n",
       "book_author             62059\n",
       "year_of_publication        95\n",
       "publisher                1523\n",
       "img_url                149570\n",
       "language                   26\n",
       "summary                 79521\n",
       "img_path               149570\n",
       "category                   15\n",
       "summary_topic             350\n",
       "category_topic            112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "book_author                0\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language                   0\n",
       "summary                67230\n",
       "img_path                   0\n",
       "category                 988\n",
       "summary_topic          67227\n",
       "category_topic         68851\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category</th>\n",
       "      <th>summary_topic</th>\n",
       "      <th>category_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>in a small town in canada clara callan relucta...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>decision in normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>here for the first time in paperback is an out...</td>\n",
       "      <td>images/0060973129.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>flu the story of the great influenza pandemic ...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>describes the great flu epidemic of 1918 an ou...</td>\n",
       "      <td>images/0374157065.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>the kitchen god s wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>a chinese immigrant who is convinced she is dy...</td>\n",
       "      <td>images/0399135782.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>what if the world s foremost military historia...</td>\n",
       "      <td>Robert Cowley</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>essays by respected military historians includ...</td>\n",
       "      <td>images/0425176428.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                         book_title  \\\n",
       "0  0002005018                                       clara callan   \n",
       "1  0060973129                               decision in normandy   \n",
       "2  0374157065  flu the story of the great influenza pandemic ...   \n",
       "3  0399135782                             the kitchen god s wife   \n",
       "4  0425176428  what if the world s foremost military historia...   \n",
       "\n",
       "            book_author  year_of_publication                 publisher  \\\n",
       "0  Richard Bruce Wright               2001.0                   Collins   \n",
       "1          Carlo D'Este               1991.0                 Perennial   \n",
       "2      Gina Bari Kolata               1999.0      Farrar Straus Giroux   \n",
       "3               Amy Tan               1991.0          Putnam Pub Group   \n",
       "4         Robert Cowley               2000.0  Berkley Publishing Group   \n",
       "\n",
       "                                             img_url language  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1  http://images.amazon.com/images/P/0060973129.0...       en   \n",
       "2  http://images.amazon.com/images/P/0374157065.0...       en   \n",
       "3  http://images.amazon.com/images/P/0399135782.0...       en   \n",
       "4  http://images.amazon.com/images/P/0425176428.0...       en   \n",
       "\n",
       "                                             summary  \\\n",
       "0  in a small town in canada clara callan relucta...   \n",
       "1  here for the first time in paperback is an out...   \n",
       "2  describes the great flu epidemic of 1918 an ou...   \n",
       "3  a chinese immigrant who is convinced she is dy...   \n",
       "4  essays by respected military historians includ...   \n",
       "\n",
       "                            img_path  category  summary_topic  category_topic  \n",
       "0  images/0002005018.01.THUMBZZZ.jpg  fiction1           -1.0           108.0  \n",
       "1  images/0060973129.01.THUMBZZZ.jpg  fiction1           -1.0            68.0  \n",
       "2  images/0374157065.01.THUMBZZZ.jpg  fiction1          131.0             6.0  \n",
       "3  images/0399135782.01.THUMBZZZ.jpg  fiction1           31.0            33.0  \n",
       "4  images/0425176428.01.THUMBZZZ.jpg  fiction1           -1.0            21.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특수문자 제거 및 소문자 변환\n",
    "import re\n",
    "merge_book['book_author'] = merge_book['book_author'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())\n",
    "merge_book['publisher'] = merge_book['publisher'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category</th>\n",
       "      <th>summary_topic</th>\n",
       "      <th>category_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>in a small town in canada clara callan relucta...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>decision in normandy</td>\n",
       "      <td>carlo deste</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>perennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>here for the first time in paperback is an out...</td>\n",
       "      <td>images/0060973129.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>flu the story of the great influenza pandemic ...</td>\n",
       "      <td>gina bari kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>farrar straus giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>describes the great flu epidemic of 1918 an ou...</td>\n",
       "      <td>images/0374157065.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>the kitchen god s wife</td>\n",
       "      <td>amy tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>putnam pub group</td>\n",
       "      <td>http://images.amazon.com/images/P/0399135782.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>a chinese immigrant who is convinced she is dy...</td>\n",
       "      <td>images/0399135782.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0425176428</td>\n",
       "      <td>what if the world s foremost military historia...</td>\n",
       "      <td>robert cowley</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>berkley publishing group</td>\n",
       "      <td>http://images.amazon.com/images/P/0425176428.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>essays by respected military historians includ...</td>\n",
       "      <td>images/0425176428.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                         book_title  \\\n",
       "0  0002005018                                       clara callan   \n",
       "1  0060973129                               decision in normandy   \n",
       "2  0374157065  flu the story of the great influenza pandemic ...   \n",
       "3  0399135782                             the kitchen god s wife   \n",
       "4  0425176428  what if the world s foremost military historia...   \n",
       "\n",
       "            book_author  year_of_publication                 publisher  \\\n",
       "0  richard bruce wright               2001.0                   collins   \n",
       "1           carlo deste               1991.0                 perennial   \n",
       "2      gina bari kolata               1999.0      farrar straus giroux   \n",
       "3               amy tan               1991.0          putnam pub group   \n",
       "4         robert cowley               2000.0  berkley publishing group   \n",
       "\n",
       "                                             img_url language  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1  http://images.amazon.com/images/P/0060973129.0...       en   \n",
       "2  http://images.amazon.com/images/P/0374157065.0...       en   \n",
       "3  http://images.amazon.com/images/P/0399135782.0...       en   \n",
       "4  http://images.amazon.com/images/P/0425176428.0...       en   \n",
       "\n",
       "                                             summary  \\\n",
       "0  in a small town in canada clara callan relucta...   \n",
       "1  here for the first time in paperback is an out...   \n",
       "2  describes the great flu epidemic of 1918 an ou...   \n",
       "3  a chinese immigrant who is convinced she is dy...   \n",
       "4  essays by respected military historians includ...   \n",
       "\n",
       "                            img_path  category  summary_topic  category_topic  \n",
       "0  images/0002005018.01.THUMBZZZ.jpg  fiction1           -1.0           108.0  \n",
       "1  images/0060973129.01.THUMBZZZ.jpg  fiction1           -1.0            68.0  \n",
       "2  images/0374157065.01.THUMBZZZ.jpg  fiction1          131.0             6.0  \n",
       "3  images/0399135782.01.THUMBZZZ.jpg  fiction1           31.0            33.0  \n",
       "4  images/0425176428.01.THUMBZZZ.jpg  fiction1           -1.0            21.0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계속 사용할 것 같아서 따로 저장 \n",
    "# merge_book.to_csv('books_v5_merge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1794840"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                 59803\n",
       "isbn                   129777\n",
       "rating                     10\n",
       "book_title             115473\n",
       "book_author             52679\n",
       "year_of_publication        92\n",
       "publisher                1402\n",
       "img_url                129777\n",
       "language                   24\n",
       "summary                 69758\n",
       "img_path               129777\n",
       "category                   15\n",
       "summary_topic             350\n",
       "category_topic            112\n",
       "location                13888\n",
       "age                        91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_ = ratings.merge(merge_book, how='left', on='isbn')\n",
    "df = merge_.merge(usersv2, how='inner', on='user_id')\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                     0\n",
       "isbn                        0\n",
       "rating                      0\n",
       "book_title                  0\n",
       "book_author                 0\n",
       "year_of_publication         0\n",
       "publisher                   0\n",
       "img_url                     0\n",
       "language                    0\n",
       "summary                119086\n",
       "img_path                    0\n",
       "category                  894\n",
       "summary_topic          119084\n",
       "category_topic         121221\n",
       "location                    0\n",
       "age                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category</th>\n",
       "      <th>summary_topic</th>\n",
       "      <th>category_topic</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>in a small town in canada clara callan relucta...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>074322678X</td>\n",
       "      <td>4</td>\n",
       "      <td>where you ll find me and other stories</td>\n",
       "      <td>ann beattie</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/074322678X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>now back in print ann beattie 39 s finest shor...</td>\n",
       "      <td>images/074322678X.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0887841740</td>\n",
       "      <td>2</td>\n",
       "      <td>the middle stories</td>\n",
       "      <td>sheila heti</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>harperbusiness</td>\n",
       "      <td>http://images.amazon.com/images/P/0887841740.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0887841740.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1552041778</td>\n",
       "      <td>2</td>\n",
       "      <td>jane doe</td>\n",
       "      <td>r j kaiser</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>firefly books ltd</td>\n",
       "      <td>http://images.amazon.com/images/P/1552041778.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1552041778.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1567407781</td>\n",
       "      <td>6</td>\n",
       "      <td>the witchfinder amos walker mystery series</td>\n",
       "      <td>loren d estleman</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>llewellyn publications</td>\n",
       "      <td>http://images.amazon.com/images/P/1567407781.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1567407781.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        isbn  rating                                  book_title  \\\n",
       "0        8  0002005018       4                                clara callan   \n",
       "1        8  074322678X       4      where you ll find me and other stories   \n",
       "2        8  0887841740       2                          the middle stories   \n",
       "3        8  1552041778       2                                    jane doe   \n",
       "4        8  1567407781       6  the witchfinder amos walker mystery series   \n",
       "\n",
       "            book_author  year_of_publication               publisher  \\\n",
       "0  richard bruce wright               2001.0                 collins   \n",
       "1           ann beattie               2002.0                  pocket   \n",
       "2           sheila heti               2004.0          harperbusiness   \n",
       "3            r j kaiser               1999.0       firefly books ltd   \n",
       "4      loren d estleman               1998.0  llewellyn publications   \n",
       "\n",
       "                                             img_url language  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1  http://images.amazon.com/images/P/074322678X.0...       en   \n",
       "2  http://images.amazon.com/images/P/0887841740.0...       en   \n",
       "3  http://images.amazon.com/images/P/1552041778.0...       en   \n",
       "4  http://images.amazon.com/images/P/1567407781.0...       en   \n",
       "\n",
       "                                             summary  \\\n",
       "0  in a small town in canada clara callan relucta...   \n",
       "1  now back in print ann beattie 39 s finest shor...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                            img_path  category  summary_topic  category_topic  \\\n",
       "0  images/0002005018.01.THUMBZZZ.jpg  fiction1           -1.0           108.0   \n",
       "1  images/074322678X.01.THUMBZZZ.jpg  fiction1           -1.0            33.0   \n",
       "2  images/0887841740.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "3  images/1552041778.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "4  images/1567407781.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "\n",
       "                 location   age  \n",
       "0  timmins,ontario,canada  32.0  \n",
       "1  timmins,ontario,canada  32.0  \n",
       "2  timmins,ontario,canada  32.0  \n",
       "3  timmins,ontario,canada  32.0  \n",
       "4  timmins,ontario,canada  32.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'].fillna('etc', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df['category']\n",
    "X_cat_topic = df['category_topic']\n",
    "X_sum_topic = df['summary_topic']\n",
    "X_author = df['book_author']\n",
    "X_publisher = df['publisher']\n",
    "X_age = df['age']\n",
    "y = df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_cat = LabelEncoder()\n",
    "le_cat_topic = LabelEncoder()\n",
    "le_sum_topic = LabelEncoder()\n",
    "le_author = LabelEncoder()\n",
    "le_publisher = LabelEncoder()\n",
    "X_cat = le_cat.fit_transform(X_cat)\n",
    "X_cat_topic = le_cat_topic.fit_transform(X_cat_topic)\n",
    "X_sum_topic = le_sum_topic.fit_transform(X_sum_topic)\n",
    "X_author = le_author.fit_transform(X_author)\n",
    "X_publisher = le_publisher.fit_transform(X_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_age = vectorizer.fit_transform(X_age.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([ # pd.Series(X_cat), \n",
    "               pd.Series(X_cat_topic), \n",
    "               pd.Series(X_sum_topic), \n",
    "               pd.Series(X_author), \n",
    "               pd.Series(X_publisher), \n",
    "               pd.DataFrame(X_age.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3], dtype='int64')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[X.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "for i, col in enumerate(X.columns):\n",
    "    if X.columns.duplicated()[i]:\n",
    "        new_columns.append(f\"{col}_{i}\")\n",
    "    else:\n",
    "        new_columns.append(col)\n",
    "X.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 10,\n",
    "    'eta': 0.5,\n",
    "    'objective': 'reg:squarederror', \n",
    "    'min_child_weight': 7,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:4.07818\n",
      "[1]\tTest-rmse:2.92106\n",
      "[2]\tTest-rmse:2.55219\n",
      "[3]\tTest-rmse:2.44712\n",
      "[4]\tTest-rmse:2.41776\n",
      "[5]\tTest-rmse:2.41208\n",
      "[6]\tTest-rmse:2.41009\n",
      "[7]\tTest-rmse:2.40457\n",
      "[8]\tTest-rmse:2.40403\n",
      "[9]\tTest-rmse:2.40226\n",
      "[10]\tTest-rmse:2.40188\n",
      "[11]\tTest-rmse:2.40154\n",
      "[12]\tTest-rmse:2.40130\n",
      "[13]\tTest-rmse:2.40109\n",
      "[14]\tTest-rmse:2.39953\n",
      "[15]\tTest-rmse:2.39618\n",
      "[16]\tTest-rmse:2.39620\n",
      "[17]\tTest-rmse:2.39610\n",
      "[18]\tTest-rmse:2.39638\n",
      "[19]\tTest-rmse:2.39625\n",
      "[20]\tTest-rmse:2.39577\n",
      "[21]\tTest-rmse:2.39562\n",
      "[22]\tTest-rmse:2.39466\n",
      "[23]\tTest-rmse:2.39465\n",
      "[24]\tTest-rmse:2.39440\n",
      "[25]\tTest-rmse:2.39459\n",
      "[26]\tTest-rmse:2.39481\n",
      "[27]\tTest-rmse:2.39427\n",
      "[28]\tTest-rmse:2.39453\n",
      "[29]\tTest-rmse:2.39433\n",
      "[30]\tTest-rmse:2.39457\n",
      "[31]\tTest-rmse:2.39409\n",
      "[32]\tTest-rmse:2.39420\n",
      "[33]\tTest-rmse:2.39458\n",
      "[34]\tTest-rmse:2.39432\n",
      "[35]\tTest-rmse:2.39476\n",
      "[36]\tTest-rmse:2.39488\n",
      "[37]\tTest-rmse:2.39497\n",
      "[38]\tTest-rmse:2.39488\n",
      "[39]\tTest-rmse:2.39490\n",
      "[40]\tTest-rmse:2.39520\n",
      "[41]\tTest-rmse:2.39553\n"
     ]
    }
   ],
   "source": [
    "num_round = 100 \n",
    "bst = xgb.train(param, dtrain, num_round,num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.39 with 32 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} with {} rounds\".format(\n",
    "                 bst.best_score,\n",
    "                 bst.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.700390</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>6.700476</td>\n",
       "      <td>0.004881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.409855</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>6.410040</td>\n",
       "      <td>0.004894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.135848</td>\n",
       "      <td>0.001041</td>\n",
       "      <td>6.136182</td>\n",
       "      <td>0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.877569</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>5.878074</td>\n",
       "      <td>0.004925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.634294</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>5.634971</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>2.262000</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>2.385621</td>\n",
       "      <td>0.010174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2.261831</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>2.385628</td>\n",
       "      <td>0.010179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>2.261709</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>2.385607</td>\n",
       "      <td>0.010173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>2.261568</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>2.385619</td>\n",
       "      <td>0.010167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>2.261441</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>2.385593</td>\n",
       "      <td>0.010195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0           6.700390        0.001136        6.700476       0.004881\n",
       "1           6.409855        0.001072        6.410040       0.004894\n",
       "2           6.135848        0.001041        6.136182       0.004921\n",
       "3           5.877569        0.001010        5.878074       0.004925\n",
       "4           5.634294        0.000916        5.634971       0.005003\n",
       "..               ...             ...             ...            ...\n",
       "666         2.262000        0.002034        2.385621       0.010174\n",
       "667         2.261831        0.002002        2.385628       0.010179\n",
       "668         2.261709        0.001999        2.385607       0.010173\n",
       "669         2.261568        0.002045        2.385619       0.010167\n",
       "670         2.261441        0.002008        2.385593       0.010195\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv( \n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=999, \n",
    "    seed=42, \n",
    "    nfold=5, \n",
    "    metrics={'rmse'}, \n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4001076951416223"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tRMSE 2.400714287310458 for 41 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tRMSE 2.398915658307208 for 26 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tRMSE 2.399430269799994 for 29 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tRMSE 2.401736702828961 for 25 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tRMSE 2.401832768722494 for 25 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tRMSE 2.4001076951416223 for 25 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tRMSE 2.4032844912250533 for 16 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tRMSE 2.4027562809294203 for 19 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tRMSE 2.402036434340466 for 18 rounds\n",
      "Best params: 9, 6, RMSE: 2.398915658307208\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "    \n",
    "    param['max_depth'] = max_depth\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['max_depth'] = 9\n",
    "param['min_child_weight'] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tRMSE 2.3987346142483372 for 29 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tRMSE 2.3980004720439445 for 34 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tRMSE 2.398648439188441 for 28 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tRMSE 2.3984340876802386 for 38 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tRMSE 2.4026657408524206 for 31 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tRMSE 2.401828322292724 for 25 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tRMSE 2.401538407865804 for 24 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tRMSE 2.398915658307208 for 26 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tRMSE 2.403521513675182 for 20 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tRMSE 2.4035721185896004 for 21 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tRMSE 2.403287458382646 for 24 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tRMSE 2.402512106712691 for 31 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tRMSE 2.4062311137810966 for 21 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tRMSE 2.4066438302565927 for 18 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tRMSE 2.405517732462129 for 23 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tRMSE 2.4036530642323806 for 19 rounds\n",
      "Best params: 1.0, 0.9, RMSE: 2.3980004720439445\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "    \n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample\n",
    "    \n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['subsample'] = 1.0\n",
    "param['colsample_bytree'] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "    \n",
    "    param['eta'] = eta\n",
    "    \n",
    "    %time cv_results = xgb.cv(param,dtrain,num_boost_round=999,seed=42,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "    \n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['eta'] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:6.68856\n",
      "[1]\tTest-rmse:6.39816\n",
      "[2]\tTest-rmse:6.12433\n",
      "[3]\tTest-rmse:5.86626\n",
      "[4]\tTest-rmse:5.62321\n",
      "[5]\tTest-rmse:5.39451\n",
      "[6]\tTest-rmse:5.17934\n",
      "[7]\tTest-rmse:4.97718\n",
      "[8]\tTest-rmse:4.78758\n",
      "[9]\tTest-rmse:4.60966\n",
      "[10]\tTest-rmse:4.44279\n",
      "[11]\tTest-rmse:4.28687\n",
      "[12]\tTest-rmse:4.14111\n",
      "[13]\tTest-rmse:4.00509\n",
      "[14]\tTest-rmse:3.87817\n",
      "[15]\tTest-rmse:3.75998\n",
      "[16]\tTest-rmse:3.65012\n",
      "[17]\tTest-rmse:3.54777\n",
      "[18]\tTest-rmse:3.45291\n",
      "[19]\tTest-rmse:3.36516\n",
      "[20]\tTest-rmse:3.28395\n",
      "[21]\tTest-rmse:3.20883\n",
      "[22]\tTest-rmse:3.13942\n",
      "[23]\tTest-rmse:3.07556\n",
      "[24]\tTest-rmse:3.01648\n",
      "[25]\tTest-rmse:2.96242\n",
      "[26]\tTest-rmse:2.91279\n",
      "[27]\tTest-rmse:2.86727\n",
      "[28]\tTest-rmse:2.82554\n",
      "[29]\tTest-rmse:2.78736\n",
      "[30]\tTest-rmse:2.75243\n",
      "[31]\tTest-rmse:2.72038\n",
      "[32]\tTest-rmse:2.69133\n",
      "[33]\tTest-rmse:2.66483\n",
      "[34]\tTest-rmse:2.64066\n",
      "[35]\tTest-rmse:2.61847\n",
      "[36]\tTest-rmse:2.59848\n",
      "[37]\tTest-rmse:2.58020\n",
      "[38]\tTest-rmse:2.56369\n",
      "[39]\tTest-rmse:2.54870\n",
      "[40]\tTest-rmse:2.53513\n",
      "[41]\tTest-rmse:2.52273\n",
      "[42]\tTest-rmse:2.51155\n",
      "[43]\tTest-rmse:2.50137\n",
      "[44]\tTest-rmse:2.49225\n",
      "[45]\tTest-rmse:2.48386\n",
      "[46]\tTest-rmse:2.47635\n",
      "[47]\tTest-rmse:2.46913\n",
      "[48]\tTest-rmse:2.46296\n",
      "[49]\tTest-rmse:2.45740\n",
      "[50]\tTest-rmse:2.45229\n",
      "[51]\tTest-rmse:2.44778\n",
      "[52]\tTest-rmse:2.44326\n",
      "[53]\tTest-rmse:2.43956\n",
      "[54]\tTest-rmse:2.43622\n",
      "[55]\tTest-rmse:2.43317\n",
      "[56]\tTest-rmse:2.43045\n",
      "[57]\tTest-rmse:2.42797\n",
      "[58]\tTest-rmse:2.42572\n",
      "[59]\tTest-rmse:2.42356\n",
      "[60]\tTest-rmse:2.42153\n",
      "[61]\tTest-rmse:2.41986\n",
      "[62]\tTest-rmse:2.41837\n",
      "[63]\tTest-rmse:2.41701\n",
      "[64]\tTest-rmse:2.41546\n",
      "[65]\tTest-rmse:2.41436\n",
      "[66]\tTest-rmse:2.41328\n",
      "[67]\tTest-rmse:2.41219\n",
      "[68]\tTest-rmse:2.41108\n",
      "[69]\tTest-rmse:2.41035\n",
      "[70]\tTest-rmse:2.40960\n",
      "[71]\tTest-rmse:2.40902\n",
      "[72]\tTest-rmse:2.40847\n",
      "[73]\tTest-rmse:2.40796\n",
      "[74]\tTest-rmse:2.40745\n",
      "[75]\tTest-rmse:2.40707\n",
      "[76]\tTest-rmse:2.40672\n",
      "[77]\tTest-rmse:2.40597\n",
      "[78]\tTest-rmse:2.40562\n",
      "[79]\tTest-rmse:2.40531\n",
      "[80]\tTest-rmse:2.40479\n",
      "[81]\tTest-rmse:2.40457\n",
      "[82]\tTest-rmse:2.40430\n",
      "[83]\tTest-rmse:2.40400\n",
      "[84]\tTest-rmse:2.40378\n",
      "[85]\tTest-rmse:2.40361\n",
      "[86]\tTest-rmse:2.40341\n",
      "[87]\tTest-rmse:2.40330\n",
      "[88]\tTest-rmse:2.40310\n",
      "[89]\tTest-rmse:2.40298\n",
      "[90]\tTest-rmse:2.40288\n",
      "[91]\tTest-rmse:2.40278\n",
      "[92]\tTest-rmse:2.40231\n",
      "[93]\tTest-rmse:2.40223\n",
      "[94]\tTest-rmse:2.40211\n",
      "[95]\tTest-rmse:2.40205\n",
      "[96]\tTest-rmse:2.40200\n",
      "[97]\tTest-rmse:2.40182\n",
      "[98]\tTest-rmse:2.40179\n",
      "[99]\tTest-rmse:2.40162\n",
      "[100]\tTest-rmse:2.40156\n",
      "[101]\tTest-rmse:2.40105\n",
      "[102]\tTest-rmse:2.40096\n",
      "[103]\tTest-rmse:2.40095\n",
      "[104]\tTest-rmse:2.40091\n",
      "[105]\tTest-rmse:2.40050\n",
      "[106]\tTest-rmse:2.40038\n",
      "[107]\tTest-rmse:2.40032\n",
      "[108]\tTest-rmse:2.40029\n",
      "[109]\tTest-rmse:2.40015\n",
      "[110]\tTest-rmse:2.40007\n",
      "[111]\tTest-rmse:2.40006\n",
      "[112]\tTest-rmse:2.39997\n",
      "[113]\tTest-rmse:2.39992\n",
      "[114]\tTest-rmse:2.39973\n",
      "[115]\tTest-rmse:2.39957\n",
      "[116]\tTest-rmse:2.39953\n",
      "[117]\tTest-rmse:2.39944\n",
      "[118]\tTest-rmse:2.39916\n",
      "[119]\tTest-rmse:2.39885\n",
      "[120]\tTest-rmse:2.39881\n",
      "[121]\tTest-rmse:2.39861\n",
      "[122]\tTest-rmse:2.39849\n",
      "[123]\tTest-rmse:2.39843\n",
      "[124]\tTest-rmse:2.39840\n",
      "[125]\tTest-rmse:2.39835\n",
      "[126]\tTest-rmse:2.39830\n",
      "[127]\tTest-rmse:2.39827\n",
      "[128]\tTest-rmse:2.39819\n",
      "[129]\tTest-rmse:2.39819\n",
      "[130]\tTest-rmse:2.39811\n",
      "[131]\tTest-rmse:2.39812\n",
      "[132]\tTest-rmse:2.39799\n",
      "[133]\tTest-rmse:2.39751\n",
      "[134]\tTest-rmse:2.39744\n",
      "[135]\tTest-rmse:2.39741\n",
      "[136]\tTest-rmse:2.39735\n",
      "[137]\tTest-rmse:2.39716\n",
      "[138]\tTest-rmse:2.39704\n",
      "[139]\tTest-rmse:2.39698\n",
      "[140]\tTest-rmse:2.39693\n",
      "[141]\tTest-rmse:2.39683\n",
      "[142]\tTest-rmse:2.39681\n",
      "[143]\tTest-rmse:2.39675\n",
      "[144]\tTest-rmse:2.39672\n",
      "[145]\tTest-rmse:2.39654\n",
      "[146]\tTest-rmse:2.39623\n",
      "[147]\tTest-rmse:2.39621\n",
      "[148]\tTest-rmse:2.39614\n",
      "[149]\tTest-rmse:2.39612\n",
      "[150]\tTest-rmse:2.39611\n",
      "[151]\tTest-rmse:2.39609\n",
      "[152]\tTest-rmse:2.39609\n",
      "[153]\tTest-rmse:2.39605\n",
      "[154]\tTest-rmse:2.39596\n",
      "[155]\tTest-rmse:2.39594\n",
      "[156]\tTest-rmse:2.39589\n",
      "[157]\tTest-rmse:2.39558\n",
      "[158]\tTest-rmse:2.39555\n",
      "[159]\tTest-rmse:2.39553\n",
      "[160]\tTest-rmse:2.39555\n",
      "[161]\tTest-rmse:2.39545\n",
      "[162]\tTest-rmse:2.39542\n",
      "[163]\tTest-rmse:2.39539\n",
      "[164]\tTest-rmse:2.39536\n",
      "[165]\tTest-rmse:2.39527\n",
      "[166]\tTest-rmse:2.39527\n",
      "[167]\tTest-rmse:2.39501\n",
      "[168]\tTest-rmse:2.39496\n",
      "[169]\tTest-rmse:2.39495\n",
      "[170]\tTest-rmse:2.39487\n",
      "[171]\tTest-rmse:2.39471\n",
      "[172]\tTest-rmse:2.39467\n",
      "[173]\tTest-rmse:2.39464\n",
      "[174]\tTest-rmse:2.39464\n",
      "[175]\tTest-rmse:2.39454\n",
      "[176]\tTest-rmse:2.39449\n",
      "[177]\tTest-rmse:2.39447\n",
      "[178]\tTest-rmse:2.39443\n",
      "[179]\tTest-rmse:2.39423\n",
      "[180]\tTest-rmse:2.39415\n",
      "[181]\tTest-rmse:2.39414\n",
      "[182]\tTest-rmse:2.39410\n",
      "[183]\tTest-rmse:2.39406\n",
      "[184]\tTest-rmse:2.39397\n",
      "[185]\tTest-rmse:2.39385\n",
      "[186]\tTest-rmse:2.39375\n",
      "[187]\tTest-rmse:2.39367\n",
      "[188]\tTest-rmse:2.39365\n",
      "[189]\tTest-rmse:2.39366\n",
      "[190]\tTest-rmse:2.39362\n",
      "[191]\tTest-rmse:2.39355\n",
      "[192]\tTest-rmse:2.39353\n",
      "[193]\tTest-rmse:2.39341\n",
      "[194]\tTest-rmse:2.39324\n",
      "[195]\tTest-rmse:2.39321\n",
      "[196]\tTest-rmse:2.39316\n",
      "[197]\tTest-rmse:2.39316\n",
      "[198]\tTest-rmse:2.39297\n",
      "[199]\tTest-rmse:2.39295\n",
      "[200]\tTest-rmse:2.39295\n",
      "[201]\tTest-rmse:2.39285\n",
      "[202]\tTest-rmse:2.39283\n",
      "[203]\tTest-rmse:2.39282\n",
      "[204]\tTest-rmse:2.39273\n",
      "[205]\tTest-rmse:2.39253\n",
      "[206]\tTest-rmse:2.39247\n",
      "[207]\tTest-rmse:2.39241\n",
      "[208]\tTest-rmse:2.39237\n",
      "[209]\tTest-rmse:2.39230\n",
      "[210]\tTest-rmse:2.39225\n",
      "[211]\tTest-rmse:2.39222\n",
      "[212]\tTest-rmse:2.39221\n",
      "[213]\tTest-rmse:2.39207\n",
      "[214]\tTest-rmse:2.39198\n",
      "[215]\tTest-rmse:2.39198\n",
      "[216]\tTest-rmse:2.39198\n",
      "[217]\tTest-rmse:2.39193\n",
      "[218]\tTest-rmse:2.39192\n",
      "[219]\tTest-rmse:2.39192\n",
      "[220]\tTest-rmse:2.39169\n",
      "[221]\tTest-rmse:2.39169\n",
      "[222]\tTest-rmse:2.39163\n",
      "[223]\tTest-rmse:2.39158\n",
      "[224]\tTest-rmse:2.39159\n",
      "[225]\tTest-rmse:2.39156\n",
      "[226]\tTest-rmse:2.39156\n",
      "[227]\tTest-rmse:2.39157\n",
      "[228]\tTest-rmse:2.39156\n",
      "[229]\tTest-rmse:2.39153\n",
      "[230]\tTest-rmse:2.39147\n",
      "[231]\tTest-rmse:2.39127\n",
      "[232]\tTest-rmse:2.39124\n",
      "[233]\tTest-rmse:2.39121\n",
      "[234]\tTest-rmse:2.39119\n",
      "[235]\tTest-rmse:2.39109\n",
      "[236]\tTest-rmse:2.39107\n",
      "[237]\tTest-rmse:2.39108\n",
      "[238]\tTest-rmse:2.39111\n",
      "[239]\tTest-rmse:2.39110\n",
      "[240]\tTest-rmse:2.39104\n",
      "[241]\tTest-rmse:2.39102\n",
      "[242]\tTest-rmse:2.39098\n",
      "[243]\tTest-rmse:2.39086\n",
      "[244]\tTest-rmse:2.39075\n",
      "[245]\tTest-rmse:2.39063\n",
      "[246]\tTest-rmse:2.39058\n",
      "[247]\tTest-rmse:2.39058\n",
      "[248]\tTest-rmse:2.39058\n",
      "[249]\tTest-rmse:2.39060\n",
      "[250]\tTest-rmse:2.39057\n",
      "[251]\tTest-rmse:2.39047\n",
      "[252]\tTest-rmse:2.39045\n",
      "[253]\tTest-rmse:2.39040\n",
      "[254]\tTest-rmse:2.39036\n",
      "[255]\tTest-rmse:2.39021\n",
      "[256]\tTest-rmse:2.39023\n",
      "[257]\tTest-rmse:2.39018\n",
      "[258]\tTest-rmse:2.39004\n",
      "[259]\tTest-rmse:2.38990\n",
      "[260]\tTest-rmse:2.38982\n",
      "[261]\tTest-rmse:2.38980\n",
      "[262]\tTest-rmse:2.38961\n",
      "[263]\tTest-rmse:2.38957\n",
      "[264]\tTest-rmse:2.38955\n",
      "[265]\tTest-rmse:2.38955\n",
      "[266]\tTest-rmse:2.38947\n",
      "[267]\tTest-rmse:2.38940\n",
      "[268]\tTest-rmse:2.38938\n",
      "[269]\tTest-rmse:2.38936\n",
      "[270]\tTest-rmse:2.38932\n",
      "[271]\tTest-rmse:2.38929\n",
      "[272]\tTest-rmse:2.38929\n",
      "[273]\tTest-rmse:2.38929\n",
      "[274]\tTest-rmse:2.38918\n",
      "[275]\tTest-rmse:2.38918\n",
      "[276]\tTest-rmse:2.38910\n",
      "[277]\tTest-rmse:2.38910\n",
      "[278]\tTest-rmse:2.38905\n",
      "[279]\tTest-rmse:2.38900\n",
      "[280]\tTest-rmse:2.38892\n",
      "[281]\tTest-rmse:2.38889\n",
      "[282]\tTest-rmse:2.38890\n",
      "[283]\tTest-rmse:2.38885\n",
      "[284]\tTest-rmse:2.38881\n",
      "[285]\tTest-rmse:2.38877\n",
      "[286]\tTest-rmse:2.38867\n",
      "[287]\tTest-rmse:2.38867\n",
      "[288]\tTest-rmse:2.38859\n",
      "[289]\tTest-rmse:2.38835\n",
      "[290]\tTest-rmse:2.38832\n",
      "[291]\tTest-rmse:2.38826\n",
      "[292]\tTest-rmse:2.38826\n",
      "[293]\tTest-rmse:2.38819\n",
      "[294]\tTest-rmse:2.38821\n",
      "[295]\tTest-rmse:2.38815\n",
      "[296]\tTest-rmse:2.38817\n",
      "[297]\tTest-rmse:2.38807\n",
      "[298]\tTest-rmse:2.38807\n",
      "[299]\tTest-rmse:2.38802\n",
      "[300]\tTest-rmse:2.38794\n",
      "[301]\tTest-rmse:2.38795\n",
      "[302]\tTest-rmse:2.38790\n",
      "[303]\tTest-rmse:2.38789\n",
      "[304]\tTest-rmse:2.38788\n",
      "[305]\tTest-rmse:2.38789\n",
      "[306]\tTest-rmse:2.38789\n",
      "[307]\tTest-rmse:2.38786\n",
      "[308]\tTest-rmse:2.38787\n",
      "[309]\tTest-rmse:2.38779\n",
      "[310]\tTest-rmse:2.38782\n",
      "[311]\tTest-rmse:2.38778\n",
      "[312]\tTest-rmse:2.38774\n",
      "[313]\tTest-rmse:2.38772\n",
      "[314]\tTest-rmse:2.38768\n",
      "[315]\tTest-rmse:2.38770\n",
      "[316]\tTest-rmse:2.38768\n",
      "[317]\tTest-rmse:2.38766\n",
      "[318]\tTest-rmse:2.38758\n",
      "[319]\tTest-rmse:2.38755\n",
      "[320]\tTest-rmse:2.38747\n",
      "[321]\tTest-rmse:2.38743\n",
      "[322]\tTest-rmse:2.38743\n",
      "[323]\tTest-rmse:2.38743\n",
      "[324]\tTest-rmse:2.38744\n",
      "[325]\tTest-rmse:2.38743\n",
      "[326]\tTest-rmse:2.38733\n",
      "[327]\tTest-rmse:2.38725\n",
      "[328]\tTest-rmse:2.38720\n",
      "[329]\tTest-rmse:2.38715\n",
      "[330]\tTest-rmse:2.38694\n",
      "[331]\tTest-rmse:2.38693\n",
      "[332]\tTest-rmse:2.38679\n",
      "[333]\tTest-rmse:2.38677\n",
      "[334]\tTest-rmse:2.38671\n",
      "[335]\tTest-rmse:2.38671\n",
      "[336]\tTest-rmse:2.38676\n",
      "[337]\tTest-rmse:2.38671\n",
      "[338]\tTest-rmse:2.38671\n",
      "[339]\tTest-rmse:2.38664\n",
      "[340]\tTest-rmse:2.38658\n",
      "[341]\tTest-rmse:2.38652\n",
      "[342]\tTest-rmse:2.38639\n",
      "[343]\tTest-rmse:2.38637\n",
      "[344]\tTest-rmse:2.38635\n",
      "[345]\tTest-rmse:2.38631\n",
      "[346]\tTest-rmse:2.38633\n",
      "[347]\tTest-rmse:2.38633\n",
      "[348]\tTest-rmse:2.38631\n",
      "[349]\tTest-rmse:2.38627\n",
      "[350]\tTest-rmse:2.38622\n",
      "[351]\tTest-rmse:2.38623\n",
      "[352]\tTest-rmse:2.38624\n",
      "[353]\tTest-rmse:2.38623\n",
      "[354]\tTest-rmse:2.38619\n",
      "[355]\tTest-rmse:2.38616\n",
      "[356]\tTest-rmse:2.38611\n",
      "[357]\tTest-rmse:2.38606\n",
      "[358]\tTest-rmse:2.38598\n",
      "[359]\tTest-rmse:2.38588\n",
      "[360]\tTest-rmse:2.38588\n",
      "[361]\tTest-rmse:2.38584\n",
      "[362]\tTest-rmse:2.38575\n",
      "[363]\tTest-rmse:2.38573\n",
      "[364]\tTest-rmse:2.38570\n",
      "[365]\tTest-rmse:2.38570\n",
      "[366]\tTest-rmse:2.38562\n",
      "[367]\tTest-rmse:2.38561\n",
      "[368]\tTest-rmse:2.38562\n",
      "[369]\tTest-rmse:2.38559\n",
      "[370]\tTest-rmse:2.38554\n",
      "[371]\tTest-rmse:2.38552\n",
      "[372]\tTest-rmse:2.38550\n",
      "[373]\tTest-rmse:2.38547\n",
      "[374]\tTest-rmse:2.38530\n",
      "[375]\tTest-rmse:2.38531\n",
      "[376]\tTest-rmse:2.38528\n",
      "[377]\tTest-rmse:2.38529\n",
      "[378]\tTest-rmse:2.38521\n",
      "[379]\tTest-rmse:2.38520\n",
      "[380]\tTest-rmse:2.38516\n",
      "[381]\tTest-rmse:2.38513\n",
      "[382]\tTest-rmse:2.38513\n",
      "[383]\tTest-rmse:2.38508\n",
      "[384]\tTest-rmse:2.38508\n",
      "[385]\tTest-rmse:2.38509\n",
      "[386]\tTest-rmse:2.38503\n",
      "[387]\tTest-rmse:2.38493\n",
      "[388]\tTest-rmse:2.38483\n",
      "[389]\tTest-rmse:2.38478\n",
      "[390]\tTest-rmse:2.38476\n",
      "[391]\tTest-rmse:2.38469\n",
      "[392]\tTest-rmse:2.38461\n",
      "[393]\tTest-rmse:2.38461\n",
      "[394]\tTest-rmse:2.38453\n",
      "[395]\tTest-rmse:2.38439\n",
      "[396]\tTest-rmse:2.38440\n",
      "[397]\tTest-rmse:2.38435\n",
      "[398]\tTest-rmse:2.38433\n",
      "[399]\tTest-rmse:2.38432\n",
      "[400]\tTest-rmse:2.38426\n",
      "[401]\tTest-rmse:2.38422\n",
      "[402]\tTest-rmse:2.38414\n",
      "[403]\tTest-rmse:2.38410\n",
      "[404]\tTest-rmse:2.38411\n",
      "[405]\tTest-rmse:2.38414\n",
      "[406]\tTest-rmse:2.38408\n",
      "[407]\tTest-rmse:2.38407\n",
      "[408]\tTest-rmse:2.38409\n",
      "[409]\tTest-rmse:2.38410\n",
      "[410]\tTest-rmse:2.38411\n",
      "[411]\tTest-rmse:2.38410\n",
      "[412]\tTest-rmse:2.38407\n",
      "[413]\tTest-rmse:2.38403\n",
      "[414]\tTest-rmse:2.38403\n",
      "[415]\tTest-rmse:2.38403\n",
      "[416]\tTest-rmse:2.38403\n",
      "[417]\tTest-rmse:2.38401\n",
      "[418]\tTest-rmse:2.38392\n",
      "[419]\tTest-rmse:2.38387\n",
      "[420]\tTest-rmse:2.38383\n",
      "[421]\tTest-rmse:2.38375\n",
      "[422]\tTest-rmse:2.38372\n",
      "[423]\tTest-rmse:2.38370\n",
      "[424]\tTest-rmse:2.38369\n",
      "[425]\tTest-rmse:2.38366\n",
      "[426]\tTest-rmse:2.38361\n",
      "[427]\tTest-rmse:2.38357\n",
      "[428]\tTest-rmse:2.38354\n",
      "[429]\tTest-rmse:2.38348\n",
      "[430]\tTest-rmse:2.38347\n",
      "[431]\tTest-rmse:2.38343\n",
      "[432]\tTest-rmse:2.38338\n",
      "[433]\tTest-rmse:2.38334\n",
      "[434]\tTest-rmse:2.38335\n",
      "[435]\tTest-rmse:2.38334\n",
      "[436]\tTest-rmse:2.38334\n",
      "[437]\tTest-rmse:2.38334\n",
      "[438]\tTest-rmse:2.38328\n",
      "[439]\tTest-rmse:2.38330\n",
      "[440]\tTest-rmse:2.38326\n",
      "[441]\tTest-rmse:2.38323\n",
      "[442]\tTest-rmse:2.38322\n",
      "[443]\tTest-rmse:2.38318\n",
      "[444]\tTest-rmse:2.38319\n",
      "[445]\tTest-rmse:2.38319\n",
      "[446]\tTest-rmse:2.38316\n",
      "[447]\tTest-rmse:2.38318\n",
      "[448]\tTest-rmse:2.38313\n",
      "[449]\tTest-rmse:2.38307\n",
      "[450]\tTest-rmse:2.38305\n",
      "[451]\tTest-rmse:2.38305\n",
      "[452]\tTest-rmse:2.38305\n",
      "[453]\tTest-rmse:2.38301\n",
      "[454]\tTest-rmse:2.38297\n",
      "[455]\tTest-rmse:2.38296\n",
      "[456]\tTest-rmse:2.38292\n",
      "[457]\tTest-rmse:2.38290\n",
      "[458]\tTest-rmse:2.38289\n",
      "[459]\tTest-rmse:2.38287\n",
      "[460]\tTest-rmse:2.38287\n",
      "[461]\tTest-rmse:2.38288\n",
      "[462]\tTest-rmse:2.38290\n",
      "[463]\tTest-rmse:2.38286\n",
      "[464]\tTest-rmse:2.38283\n",
      "[465]\tTest-rmse:2.38282\n",
      "[466]\tTest-rmse:2.38276\n",
      "[467]\tTest-rmse:2.38274\n",
      "[468]\tTest-rmse:2.38273\n",
      "[469]\tTest-rmse:2.38272\n",
      "[470]\tTest-rmse:2.38266\n",
      "[471]\tTest-rmse:2.38264\n",
      "[472]\tTest-rmse:2.38266\n",
      "[473]\tTest-rmse:2.38259\n",
      "[474]\tTest-rmse:2.38255\n",
      "[475]\tTest-rmse:2.38256\n",
      "[476]\tTest-rmse:2.38256\n",
      "[477]\tTest-rmse:2.38254\n",
      "[478]\tTest-rmse:2.38243\n",
      "[479]\tTest-rmse:2.38238\n",
      "[480]\tTest-rmse:2.38233\n",
      "[481]\tTest-rmse:2.38234\n",
      "[482]\tTest-rmse:2.38229\n",
      "[483]\tTest-rmse:2.38226\n",
      "[484]\tTest-rmse:2.38220\n",
      "[485]\tTest-rmse:2.38219\n",
      "[486]\tTest-rmse:2.38217\n",
      "[487]\tTest-rmse:2.38216\n",
      "[488]\tTest-rmse:2.38218\n",
      "[489]\tTest-rmse:2.38214\n",
      "[490]\tTest-rmse:2.38209\n",
      "[491]\tTest-rmse:2.38206\n",
      "[492]\tTest-rmse:2.38201\n",
      "[493]\tTest-rmse:2.38202\n",
      "[494]\tTest-rmse:2.38202\n",
      "[495]\tTest-rmse:2.38201\n",
      "[496]\tTest-rmse:2.38198\n",
      "[497]\tTest-rmse:2.38195\n",
      "[498]\tTest-rmse:2.38198\n",
      "[499]\tTest-rmse:2.38195\n",
      "[500]\tTest-rmse:2.38196\n",
      "[501]\tTest-rmse:2.38197\n",
      "[502]\tTest-rmse:2.38198\n",
      "[503]\tTest-rmse:2.38195\n",
      "[504]\tTest-rmse:2.38189\n",
      "[505]\tTest-rmse:2.38186\n",
      "[506]\tTest-rmse:2.38183\n",
      "[507]\tTest-rmse:2.38183\n",
      "[508]\tTest-rmse:2.38183\n",
      "[509]\tTest-rmse:2.38179\n",
      "[510]\tTest-rmse:2.38177\n",
      "[511]\tTest-rmse:2.38179\n",
      "[512]\tTest-rmse:2.38181\n",
      "[513]\tTest-rmse:2.38179\n",
      "[514]\tTest-rmse:2.38179\n",
      "[515]\tTest-rmse:2.38177\n",
      "[516]\tTest-rmse:2.38176\n",
      "[517]\tTest-rmse:2.38170\n",
      "[518]\tTest-rmse:2.38169\n",
      "[519]\tTest-rmse:2.38170\n",
      "[520]\tTest-rmse:2.38165\n",
      "[521]\tTest-rmse:2.38164\n",
      "[522]\tTest-rmse:2.38163\n",
      "[523]\tTest-rmse:2.38156\n",
      "[524]\tTest-rmse:2.38157\n",
      "[525]\tTest-rmse:2.38156\n",
      "[526]\tTest-rmse:2.38156\n",
      "[527]\tTest-rmse:2.38154\n",
      "[528]\tTest-rmse:2.38153\n",
      "[529]\tTest-rmse:2.38154\n",
      "[530]\tTest-rmse:2.38153\n",
      "[531]\tTest-rmse:2.38149\n",
      "[532]\tTest-rmse:2.38149\n",
      "[533]\tTest-rmse:2.38148\n",
      "[534]\tTest-rmse:2.38148\n",
      "[535]\tTest-rmse:2.38149\n",
      "[536]\tTest-rmse:2.38144\n",
      "[537]\tTest-rmse:2.38143\n",
      "[538]\tTest-rmse:2.38138\n",
      "[539]\tTest-rmse:2.38131\n",
      "[540]\tTest-rmse:2.38128\n",
      "[541]\tTest-rmse:2.38125\n",
      "[542]\tTest-rmse:2.38123\n",
      "[543]\tTest-rmse:2.38121\n",
      "[544]\tTest-rmse:2.38117\n",
      "[545]\tTest-rmse:2.38113\n",
      "[546]\tTest-rmse:2.38111\n",
      "[547]\tTest-rmse:2.38110\n",
      "[548]\tTest-rmse:2.38103\n",
      "[549]\tTest-rmse:2.38102\n",
      "[550]\tTest-rmse:2.38102\n",
      "[551]\tTest-rmse:2.38101\n",
      "[552]\tTest-rmse:2.38101\n",
      "[553]\tTest-rmse:2.38098\n",
      "[554]\tTest-rmse:2.38098\n",
      "[555]\tTest-rmse:2.38099\n",
      "[556]\tTest-rmse:2.38094\n",
      "[557]\tTest-rmse:2.38095\n",
      "[558]\tTest-rmse:2.38094\n",
      "[559]\tTest-rmse:2.38093\n",
      "[560]\tTest-rmse:2.38094\n",
      "[561]\tTest-rmse:2.38093\n",
      "[562]\tTest-rmse:2.38091\n",
      "[563]\tTest-rmse:2.38090\n",
      "[564]\tTest-rmse:2.38088\n",
      "[565]\tTest-rmse:2.38088\n",
      "[566]\tTest-rmse:2.38085\n",
      "[567]\tTest-rmse:2.38085\n",
      "[568]\tTest-rmse:2.38079\n",
      "[569]\tTest-rmse:2.38078\n",
      "[570]\tTest-rmse:2.38077\n",
      "[571]\tTest-rmse:2.38079\n",
      "[572]\tTest-rmse:2.38077\n",
      "[573]\tTest-rmse:2.38077\n",
      "[574]\tTest-rmse:2.38077\n",
      "[575]\tTest-rmse:2.38077\n",
      "[576]\tTest-rmse:2.38077\n",
      "[577]\tTest-rmse:2.38075\n",
      "[578]\tTest-rmse:2.38075\n",
      "[579]\tTest-rmse:2.38074\n",
      "[580]\tTest-rmse:2.38074\n",
      "[581]\tTest-rmse:2.38074\n",
      "[582]\tTest-rmse:2.38073\n",
      "[583]\tTest-rmse:2.38072\n",
      "[584]\tTest-rmse:2.38067\n",
      "[585]\tTest-rmse:2.38066\n",
      "[586]\tTest-rmse:2.38066\n",
      "[587]\tTest-rmse:2.38063\n",
      "[588]\tTest-rmse:2.38061\n",
      "[589]\tTest-rmse:2.38060\n",
      "[590]\tTest-rmse:2.38056\n",
      "[591]\tTest-rmse:2.38056\n",
      "[592]\tTest-rmse:2.38054\n",
      "[593]\tTest-rmse:2.38053\n",
      "[594]\tTest-rmse:2.38053\n",
      "[595]\tTest-rmse:2.38045\n",
      "[596]\tTest-rmse:2.38045\n",
      "[597]\tTest-rmse:2.38038\n",
      "[598]\tTest-rmse:2.38039\n",
      "[599]\tTest-rmse:2.38037\n",
      "[600]\tTest-rmse:2.38036\n",
      "[601]\tTest-rmse:2.38034\n",
      "[602]\tTest-rmse:2.38030\n",
      "[603]\tTest-rmse:2.38031\n",
      "[604]\tTest-rmse:2.38028\n",
      "[605]\tTest-rmse:2.38028\n",
      "[606]\tTest-rmse:2.38025\n",
      "[607]\tTest-rmse:2.38028\n",
      "[608]\tTest-rmse:2.38025\n",
      "[609]\tTest-rmse:2.38023\n",
      "[610]\tTest-rmse:2.38021\n",
      "[611]\tTest-rmse:2.38017\n",
      "[612]\tTest-rmse:2.38014\n",
      "[613]\tTest-rmse:2.38002\n",
      "[614]\tTest-rmse:2.38000\n",
      "[615]\tTest-rmse:2.37996\n",
      "[616]\tTest-rmse:2.37996\n",
      "[617]\tTest-rmse:2.37995\n",
      "[618]\tTest-rmse:2.37992\n",
      "[619]\tTest-rmse:2.37991\n",
      "[620]\tTest-rmse:2.37986\n",
      "[621]\tTest-rmse:2.37985\n",
      "[622]\tTest-rmse:2.37986\n",
      "[623]\tTest-rmse:2.37982\n",
      "[624]\tTest-rmse:2.37981\n",
      "[625]\tTest-rmse:2.37979\n",
      "[626]\tTest-rmse:2.37974\n",
      "[627]\tTest-rmse:2.37973\n",
      "[628]\tTest-rmse:2.37975\n",
      "[629]\tTest-rmse:2.37974\n",
      "[630]\tTest-rmse:2.37977\n",
      "[631]\tTest-rmse:2.37978\n",
      "[632]\tTest-rmse:2.37976\n",
      "[633]\tTest-rmse:2.37977\n",
      "[634]\tTest-rmse:2.37983\n",
      "[635]\tTest-rmse:2.37984\n",
      "[636]\tTest-rmse:2.37983\n"
     ]
    }
   ],
   "source": [
    "# 최종 Test\n",
    "model = xgb.train(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.38 in 628 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'eta': 0.05,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'min_child_weight': 6,\n",
       " 'subsample': 1.0,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv( \n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=999, \n",
    "    seed=42, \n",
    "    nfold=5, \n",
    "    metrics={'rmse'}, \n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주의님 데이터에서 dropna로 성능만 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbn                       0\n",
       "book_title                 0\n",
       "book_author                0\n",
       "year_of_publication        0\n",
       "publisher                  0\n",
       "img_url                    0\n",
       "language                   0\n",
       "summary                67230\n",
       "img_path                   0\n",
       "category                 988\n",
       "summary_topic          67227\n",
       "category_topic         68851\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_book.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                43364\n",
       "isbn                   70680\n",
       "rating                    10\n",
       "book_title             65404\n",
       "book_author            32999\n",
       "year_of_publication       82\n",
       "publisher                745\n",
       "img_url                70680\n",
       "language                  24\n",
       "summary                68365\n",
       "img_path               70680\n",
       "category                  15\n",
       "summary_topic            350\n",
       "category_topic           112\n",
       "location               10765\n",
       "age                       88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge 후 최종 데이터 \n",
    "drop_merge = ratings.merge(merge_book, how='left', on='isbn')\n",
    "drop_df = drop_merge.merge(usersv2, how='inner', on='user_id')\n",
    "drop_df = drop_df.dropna()\n",
    "drop_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                0\n",
       "isbn                   0\n",
       "rating                 0\n",
       "book_title             0\n",
       "book_author            0\n",
       "year_of_publication    0\n",
       "publisher              0\n",
       "img_url                0\n",
       "language               0\n",
       "summary                0\n",
       "img_path               0\n",
       "category               0\n",
       "summary_topic          0\n",
       "category_topic         0\n",
       "location               0\n",
       "age                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = drop_df['category']\n",
    "X_cat_topic = drop_df['category_topic']\n",
    "X_sum_topic = drop_df['summary_topic']\n",
    "X_author = drop_df['book_author']\n",
    "X_publisher = drop_df['publisher']\n",
    "X_age = drop_df['age']\n",
    "y = drop_df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_cat = LabelEncoder()\n",
    "le_cat_topic = LabelEncoder()\n",
    "le_sum_topic = LabelEncoder()\n",
    "le_author = LabelEncoder()\n",
    "le_publisher = LabelEncoder()\n",
    "X_cat = le_cat.fit_transform(X_cat)\n",
    "X_cat_topic = le_cat_topic.fit_transform(X_cat_topic)\n",
    "X_sum_topic = le_sum_topic.fit_transform(X_sum_topic)\n",
    "X_author = le_author.fit_transform(X_author)\n",
    "X_publisher = le_publisher.fit_transform(X_author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_age = vectorizer.fit_transform(X_age.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([pd.Series(X_cat), \n",
    "               pd.Series(X_cat_topic), \n",
    "               pd.Series(X_sum_topic), \n",
    "               pd.Series(X_author), \n",
    "               pd.Series(X_publisher), \n",
    "               pd.DataFrame(X_age.toarray())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[X.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = []\n",
    "for i, col in enumerate(X.columns):\n",
    "    if X.columns.duplicated()[i]:\n",
    "        new_columns.append(f\"{col}_{i}\")\n",
    "    else:\n",
    "        new_columns.append(col)\n",
    "X.columns = new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 10, \n",
    "    'eta': 0.5, \n",
    "    'objective': 'reg:squarederror', \n",
    "    'min_child_weight': 7,\n",
    "    'subsample': 0.9,\n",
    "    'colsample_bytree': 0.7\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:4.08375\n",
      "[1]\tTest-rmse:2.92138\n",
      "[2]\tTest-rmse:2.55056\n",
      "[3]\tTest-rmse:2.44858\n",
      "[4]\tTest-rmse:2.42247\n",
      "[5]\tTest-rmse:2.41692\n",
      "[6]\tTest-rmse:2.41472\n",
      "[7]\tTest-rmse:2.41099\n",
      "[8]\tTest-rmse:2.41161\n",
      "[9]\tTest-rmse:2.41159\n",
      "[10]\tTest-rmse:2.41218\n",
      "[11]\tTest-rmse:2.41212\n",
      "[12]\tTest-rmse:2.41131\n",
      "[13]\tTest-rmse:2.41147\n",
      "[14]\tTest-rmse:2.41125\n",
      "[15]\tTest-rmse:2.41079\n",
      "[16]\tTest-rmse:2.40942\n",
      "[17]\tTest-rmse:2.40954\n",
      "[18]\tTest-rmse:2.40985\n",
      "[19]\tTest-rmse:2.40954\n",
      "[20]\tTest-rmse:2.40949\n",
      "[21]\tTest-rmse:2.40938\n",
      "[22]\tTest-rmse:2.40923\n",
      "[23]\tTest-rmse:2.40826\n",
      "[24]\tTest-rmse:2.40819\n",
      "[25]\tTest-rmse:2.40932\n",
      "[26]\tTest-rmse:2.40987\n",
      "[27]\tTest-rmse:2.40985\n",
      "[28]\tTest-rmse:2.40995\n",
      "[29]\tTest-rmse:2.40997\n",
      "[30]\tTest-rmse:2.40963\n",
      "[31]\tTest-rmse:2.41032\n",
      "[32]\tTest-rmse:2.41063\n",
      "[33]\tTest-rmse:2.41054\n"
     ]
    }
   ],
   "source": [
    "num_round = 100  # 트리 개수\n",
    "bst = xgb.train(param, dtrain, num_round,num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.41 with 25 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} with {} rounds\".format(\n",
    "                 bst.best_score,\n",
    "                 bst.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-rmse-mean</th>\n",
       "      <th>train-rmse-std</th>\n",
       "      <th>test-rmse-mean</th>\n",
       "      <th>test-rmse-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.086951</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>4.088941</td>\n",
       "      <td>0.010058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.910200</td>\n",
       "      <td>0.006031</td>\n",
       "      <td>2.919388</td>\n",
       "      <td>0.009609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.519414</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>2.540180</td>\n",
       "      <td>0.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.407134</td>\n",
       "      <td>0.006159</td>\n",
       "      <td>2.434927</td>\n",
       "      <td>0.009739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.370668</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>2.405858</td>\n",
       "      <td>0.011499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.357177</td>\n",
       "      <td>0.005737</td>\n",
       "      <td>2.397989</td>\n",
       "      <td>0.011983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.350372</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>2.395885</td>\n",
       "      <td>0.011778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.344192</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>2.394348</td>\n",
       "      <td>0.011644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.339313</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>2.394449</td>\n",
       "      <td>0.011530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.333945</td>\n",
       "      <td>0.004911</td>\n",
       "      <td>2.394616</td>\n",
       "      <td>0.012249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.329733</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>2.394067</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.326661</td>\n",
       "      <td>0.001988</td>\n",
       "      <td>2.393800</td>\n",
       "      <td>0.012434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.321838</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>2.393066</td>\n",
       "      <td>0.011535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.317964</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>2.392887</td>\n",
       "      <td>0.011535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "0          4.086951        0.003645        4.088941       0.010058\n",
       "1          2.910200        0.006031        2.919388       0.009609\n",
       "2          2.519414        0.003764        2.540180       0.010582\n",
       "3          2.407134        0.006159        2.434927       0.009739\n",
       "4          2.370668        0.004691        2.405858       0.011499\n",
       "5          2.357177        0.005737        2.397989       0.011983\n",
       "6          2.350372        0.005488        2.395885       0.011778\n",
       "7          2.344192        0.004606        2.394348       0.011644\n",
       "8          2.339313        0.004691        2.394449       0.011530\n",
       "9          2.333945        0.004911        2.394616       0.012249\n",
       "10         2.329733        0.003031        2.394067       0.012400\n",
       "11         2.326661        0.001988        2.393800       0.012434\n",
       "12         2.321838        0.001727        2.393066       0.011535\n",
       "13         2.317964        0.002274        2.392887       0.011535"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = xgb.cv( \n",
    "    param, \n",
    "    dtrain, \n",
    "    num_boost_round=999, \n",
    "    seed=42, \n",
    "    nfold=5, \n",
    "    metrics={'rmse'}, \n",
    "    early_stopping_rounds=10 \n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3928867293254497"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(9,12)\n",
    "    for min_child_weight in range(5,8)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with max_depth=9, min_child_weight=5\n",
      "\tRMSE 2.3941712781561506 for 17 rounds\n",
      "CV with max_depth=9, min_child_weight=6\n",
      "\tRMSE 2.394871836186971 for 12 rounds\n",
      "CV with max_depth=9, min_child_weight=7\n",
      "\tRMSE 2.3932704441115584 for 14 rounds\n",
      "CV with max_depth=10, min_child_weight=5\n",
      "\tRMSE 2.3955605532204958 for 12 rounds\n",
      "CV with max_depth=10, min_child_weight=6\n",
      "\tRMSE 2.3941059703430634 for 12 rounds\n",
      "CV with max_depth=10, min_child_weight=7\n",
      "\tRMSE 2.3928867293254497 for 13 rounds\n",
      "CV with max_depth=11, min_child_weight=5\n",
      "\tRMSE 2.3973484470485493 for 13 rounds\n",
      "CV with max_depth=11, min_child_weight=6\n",
      "\tRMSE 2.3983611301867227 for 7 rounds\n",
      "CV with max_depth=11, min_child_weight=7\n",
      "\tRMSE 2.3946816586872575 for 8 rounds\n",
      "Best params: 10, 7, RMSE: 2.3928867293254497\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    param['max_depth'] = max_depth\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['max_depth'] = 10\n",
    "param['min_child_weight'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(7,11)]\n",
    "    for colsample in [i/10. for i in range(7,11)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV with subsample=1.0, colsample=1.0\n",
      "\tRMSE 2.395106292139295 for 8 rounds\n",
      "CV with subsample=1.0, colsample=0.9\n",
      "\tRMSE 2.395765336233732 for 14 rounds\n",
      "CV with subsample=1.0, colsample=0.8\n",
      "\tRMSE 2.3941049840679867 for 20 rounds\n",
      "CV with subsample=1.0, colsample=0.7\n",
      "\tRMSE 2.3932044980489104 for 12 rounds\n",
      "CV with subsample=0.9, colsample=1.0\n",
      "\tRMSE 2.3966264966413235 for 8 rounds\n",
      "CV with subsample=0.9, colsample=0.9\n",
      "\tRMSE 2.3948105353706097 for 11 rounds\n",
      "CV with subsample=0.9, colsample=0.8\n",
      "\tRMSE 2.395609800658901 for 13 rounds\n",
      "CV with subsample=0.9, colsample=0.7\n",
      "\tRMSE 2.3928867293254497 for 13 rounds\n",
      "CV with subsample=0.8, colsample=1.0\n",
      "\tRMSE 2.3982658962760377 for 11 rounds\n",
      "CV with subsample=0.8, colsample=0.9\n",
      "\tRMSE 2.398234544671859 for 8 rounds\n",
      "CV with subsample=0.8, colsample=0.8\n",
      "\tRMSE 2.3972249819225393 for 8 rounds\n",
      "CV with subsample=0.8, colsample=0.7\n",
      "\tRMSE 2.3971540008724226 for 16 rounds\n",
      "CV with subsample=0.7, colsample=1.0\n",
      "\tRMSE 2.399448286484978 for 7 rounds\n",
      "CV with subsample=0.7, colsample=0.9\n",
      "\tRMSE 2.4007012965982915 for 7 rounds\n",
      "CV with subsample=0.7, colsample=0.8\n",
      "\tRMSE 2.3987297566288848 for 9 rounds\n",
      "CV with subsample=0.7, colsample=0.7\n",
      "\tRMSE 2.3987381018235348 for 14 rounds\n",
      "Best params: 0.9, 0.7, RMSE: 2.3928867293254497\n"
     ]
    }
   ],
   "source": [
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample\n",
    "\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=999,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = (subsample,colsample)\n",
    "print(\"Best params: {}, {}, RMSE: {}\".format(best_params[0], best_params[1], min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['subsample'] = 0.9\n",
    "param['colsample_bytree'] = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 7.15 µs\n",
      "CV with eta=0.3\n",
      "CPU times: user 3min 26s, sys: 632 ms, total: 3min 26s\n",
      "Wall time: 27.5 s\n",
      "\tRMSE 2.3858414736242652 for 38 rounds\n",
      "\n",
      "CV with eta=0.2\n",
      "CPU times: user 6min 23s, sys: 856 ms, total: 6min 24s\n",
      "Wall time: 49.8 s\n",
      "\tRMSE 2.381420386752217 for 86 rounds\n",
      "\n",
      "CV with eta=0.1\n",
      "CPU times: user 13min 54s, sys: 1.55 s, total: 13min 56s\n",
      "Wall time: 1min 46s\n",
      "\tRMSE 2.3754456830275634 for 200 rounds\n",
      "\n",
      "CV with eta=0.05\n",
      "CPU times: user 26min 38s, sys: 2.41 s, total: 26min 40s\n",
      "Wall time: 3min 24s\n",
      "\tRMSE 2.373027096400185 for 392 rounds\n",
      "\n",
      "CV with eta=0.01\n",
      "CPU times: user 1h 6min 12s, sys: 6.24 s, total: 1h 6min 18s\n",
      "Wall time: 8min 26s\n",
      "\tRMSE 2.3766976720868422 for 998 rounds\n",
      "\n",
      "CV with eta=0.005\n",
      "CPU times: user 1h 7min 56s, sys: 8.15 s, total: 1h 8min 4s\n",
      "Wall time: 8min 43s\n",
      "\tRMSE 2.3847519984919336 for 998 rounds\n",
      "\n",
      "Best params: 0.05, RMSE: 2.373027096400185\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "min_rmse = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [.3, .2, .1, .05, .01, .005]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    param['eta'] = eta\n",
    "\n",
    "    %time cv_results = xgb.cv(param,dtrain,num_boost_round=999,seed=42,nfold=5,metrics=['rmse'],early_stopping_rounds=10)\n",
    "\n",
    "    mean_rmse = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {} for {} rounds\\n\".format(mean_rmse, boost_rounds))\n",
    "    if mean_rmse < min_rmse:\n",
    "        min_rmse = mean_rmse\n",
    "        best_params = eta\n",
    "print(\"Best params: {}, RMSE: {}\".format(best_params, min_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['eta'] = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'eta': 0.05,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'min_child_weight': 7,\n",
       " 'subsample': 0.9,\n",
       " 'colsample_bytree': 0.7}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-rmse:6.70338\n",
      "[1]\tTest-rmse:6.41247\n",
      "[2]\tTest-rmse:6.13798\n",
      "[3]\tTest-rmse:5.87912\n",
      "[4]\tTest-rmse:5.63529\n",
      "[5]\tTest-rmse:5.40588\n",
      "[6]\tTest-rmse:5.19000\n",
      "[7]\tTest-rmse:4.98740\n",
      "[8]\tTest-rmse:4.79725\n",
      "[9]\tTest-rmse:4.61887\n",
      "[10]\tTest-rmse:4.45208\n",
      "[11]\tTest-rmse:4.29563\n",
      "[12]\tTest-rmse:4.14970\n",
      "[13]\tTest-rmse:4.01325\n",
      "[14]\tTest-rmse:3.88566\n",
      "[15]\tTest-rmse:3.76712\n",
      "[16]\tTest-rmse:3.65669\n",
      "[17]\tTest-rmse:3.55444\n",
      "[18]\tTest-rmse:3.45956\n",
      "[19]\tTest-rmse:3.37147\n",
      "[20]\tTest-rmse:3.28998\n",
      "[21]\tTest-rmse:3.21462\n",
      "[22]\tTest-rmse:3.14504\n",
      "[23]\tTest-rmse:3.08096\n",
      "[24]\tTest-rmse:3.02178\n",
      "[25]\tTest-rmse:2.96751\n",
      "[26]\tTest-rmse:2.91760\n",
      "[27]\tTest-rmse:2.87203\n",
      "[28]\tTest-rmse:2.83018\n",
      "[29]\tTest-rmse:2.79182\n",
      "[30]\tTest-rmse:2.75674\n",
      "[31]\tTest-rmse:2.72441\n",
      "[32]\tTest-rmse:2.69512\n",
      "[33]\tTest-rmse:2.66793\n",
      "[34]\tTest-rmse:2.64313\n",
      "[35]\tTest-rmse:2.62092\n",
      "[36]\tTest-rmse:2.60071\n",
      "[37]\tTest-rmse:2.58255\n",
      "[38]\tTest-rmse:2.56603\n",
      "[39]\tTest-rmse:2.55096\n",
      "[40]\tTest-rmse:2.53728\n",
      "[41]\tTest-rmse:2.52475\n",
      "[42]\tTest-rmse:2.51343\n",
      "[43]\tTest-rmse:2.50324\n",
      "[44]\tTest-rmse:2.49384\n",
      "[45]\tTest-rmse:2.48549\n",
      "[46]\tTest-rmse:2.47780\n",
      "[47]\tTest-rmse:2.47104\n",
      "[48]\tTest-rmse:2.46471\n",
      "[49]\tTest-rmse:2.45912\n",
      "[50]\tTest-rmse:2.45406\n",
      "[51]\tTest-rmse:2.44937\n",
      "[52]\tTest-rmse:2.44534\n",
      "[53]\tTest-rmse:2.44107\n",
      "[54]\tTest-rmse:2.43762\n",
      "[55]\tTest-rmse:2.43461\n",
      "[56]\tTest-rmse:2.43194\n",
      "[57]\tTest-rmse:2.42947\n",
      "[58]\tTest-rmse:2.42717\n",
      "[59]\tTest-rmse:2.42520\n",
      "[60]\tTest-rmse:2.42332\n",
      "[61]\tTest-rmse:2.42140\n",
      "[62]\tTest-rmse:2.41970\n",
      "[63]\tTest-rmse:2.41840\n",
      "[64]\tTest-rmse:2.41675\n",
      "[65]\tTest-rmse:2.41563\n",
      "[66]\tTest-rmse:2.41467\n",
      "[67]\tTest-rmse:2.41373\n",
      "[68]\tTest-rmse:2.41278\n",
      "[69]\tTest-rmse:2.41193\n",
      "[70]\tTest-rmse:2.41116\n",
      "[71]\tTest-rmse:2.41051\n",
      "[72]\tTest-rmse:2.40962\n",
      "[73]\tTest-rmse:2.40906\n",
      "[74]\tTest-rmse:2.40861\n",
      "[75]\tTest-rmse:2.40820\n",
      "[76]\tTest-rmse:2.40789\n",
      "[77]\tTest-rmse:2.40757\n",
      "[78]\tTest-rmse:2.40727\n",
      "[79]\tTest-rmse:2.40698\n",
      "[80]\tTest-rmse:2.40677\n",
      "[81]\tTest-rmse:2.40632\n",
      "[82]\tTest-rmse:2.40607\n",
      "[83]\tTest-rmse:2.40586\n",
      "[84]\tTest-rmse:2.40538\n",
      "[85]\tTest-rmse:2.40525\n",
      "[86]\tTest-rmse:2.40517\n",
      "[87]\tTest-rmse:2.40475\n",
      "[88]\tTest-rmse:2.40459\n",
      "[89]\tTest-rmse:2.40420\n",
      "[90]\tTest-rmse:2.40382\n",
      "[91]\tTest-rmse:2.40367\n",
      "[92]\tTest-rmse:2.40361\n",
      "[93]\tTest-rmse:2.40353\n",
      "[94]\tTest-rmse:2.40335\n",
      "[95]\tTest-rmse:2.40334\n",
      "[96]\tTest-rmse:2.40316\n",
      "[97]\tTest-rmse:2.40283\n",
      "[98]\tTest-rmse:2.40272\n",
      "[99]\tTest-rmse:2.40256\n",
      "[100]\tTest-rmse:2.40250\n",
      "[101]\tTest-rmse:2.40232\n",
      "[102]\tTest-rmse:2.40195\n",
      "[103]\tTest-rmse:2.40188\n",
      "[104]\tTest-rmse:2.40182\n",
      "[105]\tTest-rmse:2.40176\n",
      "[106]\tTest-rmse:2.40151\n",
      "[107]\tTest-rmse:2.40134\n",
      "[108]\tTest-rmse:2.40128\n",
      "[109]\tTest-rmse:2.40117\n",
      "[110]\tTest-rmse:2.40101\n",
      "[111]\tTest-rmse:2.40097\n",
      "[112]\tTest-rmse:2.40090\n",
      "[113]\tTest-rmse:2.40063\n",
      "[114]\tTest-rmse:2.40060\n",
      "[115]\tTest-rmse:2.40058\n",
      "[116]\tTest-rmse:2.40046\n",
      "[117]\tTest-rmse:2.40037\n",
      "[118]\tTest-rmse:2.40029\n",
      "[119]\tTest-rmse:2.40020\n",
      "[120]\tTest-rmse:2.40022\n",
      "[121]\tTest-rmse:2.40019\n",
      "[122]\tTest-rmse:2.40017\n",
      "[123]\tTest-rmse:2.40007\n",
      "[124]\tTest-rmse:2.40006\n",
      "[125]\tTest-rmse:2.40001\n",
      "[126]\tTest-rmse:2.39998\n",
      "[127]\tTest-rmse:2.39974\n",
      "[128]\tTest-rmse:2.39972\n",
      "[129]\tTest-rmse:2.39962\n",
      "[130]\tTest-rmse:2.39943\n",
      "[131]\tTest-rmse:2.39924\n",
      "[132]\tTest-rmse:2.39894\n",
      "[133]\tTest-rmse:2.39872\n",
      "[134]\tTest-rmse:2.39867\n",
      "[135]\tTest-rmse:2.39851\n",
      "[136]\tTest-rmse:2.39837\n",
      "[137]\tTest-rmse:2.39821\n",
      "[138]\tTest-rmse:2.39821\n",
      "[139]\tTest-rmse:2.39819\n",
      "[140]\tTest-rmse:2.39817\n",
      "[141]\tTest-rmse:2.39810\n",
      "[142]\tTest-rmse:2.39789\n",
      "[143]\tTest-rmse:2.39781\n",
      "[144]\tTest-rmse:2.39774\n",
      "[145]\tTest-rmse:2.39749\n",
      "[146]\tTest-rmse:2.39750\n",
      "[147]\tTest-rmse:2.39746\n",
      "[148]\tTest-rmse:2.39730\n",
      "[149]\tTest-rmse:2.39724\n",
      "[150]\tTest-rmse:2.39718\n",
      "[151]\tTest-rmse:2.39704\n",
      "[152]\tTest-rmse:2.39687\n",
      "[153]\tTest-rmse:2.39674\n",
      "[154]\tTest-rmse:2.39668\n",
      "[155]\tTest-rmse:2.39668\n",
      "[156]\tTest-rmse:2.39643\n",
      "[157]\tTest-rmse:2.39639\n",
      "[158]\tTest-rmse:2.39633\n",
      "[159]\tTest-rmse:2.39615\n",
      "[160]\tTest-rmse:2.39592\n",
      "[161]\tTest-rmse:2.39573\n",
      "[162]\tTest-rmse:2.39573\n",
      "[163]\tTest-rmse:2.39568\n",
      "[164]\tTest-rmse:2.39568\n",
      "[165]\tTest-rmse:2.39561\n",
      "[166]\tTest-rmse:2.39545\n",
      "[167]\tTest-rmse:2.39544\n",
      "[168]\tTest-rmse:2.39536\n",
      "[169]\tTest-rmse:2.39528\n",
      "[170]\tTest-rmse:2.39523\n",
      "[171]\tTest-rmse:2.39517\n",
      "[172]\tTest-rmse:2.39518\n",
      "[173]\tTest-rmse:2.39514\n",
      "[174]\tTest-rmse:2.39504\n",
      "[175]\tTest-rmse:2.39505\n",
      "[176]\tTest-rmse:2.39499\n",
      "[177]\tTest-rmse:2.39494\n",
      "[178]\tTest-rmse:2.39497\n",
      "[179]\tTest-rmse:2.39477\n",
      "[180]\tTest-rmse:2.39467\n",
      "[181]\tTest-rmse:2.39464\n",
      "[182]\tTest-rmse:2.39453\n",
      "[183]\tTest-rmse:2.39440\n",
      "[184]\tTest-rmse:2.39427\n",
      "[185]\tTest-rmse:2.39427\n",
      "[186]\tTest-rmse:2.39428\n",
      "[187]\tTest-rmse:2.39426\n",
      "[188]\tTest-rmse:2.39417\n",
      "[189]\tTest-rmse:2.39420\n",
      "[190]\tTest-rmse:2.39419\n",
      "[191]\tTest-rmse:2.39414\n",
      "[192]\tTest-rmse:2.39406\n",
      "[193]\tTest-rmse:2.39407\n",
      "[194]\tTest-rmse:2.39408\n",
      "[195]\tTest-rmse:2.39395\n",
      "[196]\tTest-rmse:2.39394\n",
      "[197]\tTest-rmse:2.39397\n",
      "[198]\tTest-rmse:2.39399\n",
      "[199]\tTest-rmse:2.39395\n",
      "[200]\tTest-rmse:2.39391\n",
      "[201]\tTest-rmse:2.39393\n",
      "[202]\tTest-rmse:2.39389\n",
      "[203]\tTest-rmse:2.39386\n",
      "[204]\tTest-rmse:2.39375\n",
      "[205]\tTest-rmse:2.39370\n",
      "[206]\tTest-rmse:2.39366\n",
      "[207]\tTest-rmse:2.39354\n",
      "[208]\tTest-rmse:2.39346\n",
      "[209]\tTest-rmse:2.39347\n",
      "[210]\tTest-rmse:2.39332\n",
      "[211]\tTest-rmse:2.39330\n",
      "[212]\tTest-rmse:2.39326\n",
      "[213]\tTest-rmse:2.39319\n",
      "[214]\tTest-rmse:2.39314\n",
      "[215]\tTest-rmse:2.39317\n",
      "[216]\tTest-rmse:2.39300\n",
      "[217]\tTest-rmse:2.39303\n",
      "[218]\tTest-rmse:2.39302\n",
      "[219]\tTest-rmse:2.39297\n",
      "[220]\tTest-rmse:2.39296\n",
      "[221]\tTest-rmse:2.39294\n",
      "[222]\tTest-rmse:2.39293\n",
      "[223]\tTest-rmse:2.39284\n",
      "[224]\tTest-rmse:2.39281\n",
      "[225]\tTest-rmse:2.39279\n",
      "[226]\tTest-rmse:2.39273\n",
      "[227]\tTest-rmse:2.39266\n",
      "[228]\tTest-rmse:2.39260\n",
      "[229]\tTest-rmse:2.39259\n",
      "[230]\tTest-rmse:2.39254\n",
      "[231]\tTest-rmse:2.39257\n",
      "[232]\tTest-rmse:2.39255\n",
      "[233]\tTest-rmse:2.39248\n",
      "[234]\tTest-rmse:2.39244\n",
      "[235]\tTest-rmse:2.39247\n",
      "[236]\tTest-rmse:2.39244\n",
      "[237]\tTest-rmse:2.39246\n",
      "[238]\tTest-rmse:2.39244\n",
      "[239]\tTest-rmse:2.39233\n",
      "[240]\tTest-rmse:2.39236\n",
      "[241]\tTest-rmse:2.39235\n",
      "[242]\tTest-rmse:2.39223\n",
      "[243]\tTest-rmse:2.39221\n",
      "[244]\tTest-rmse:2.39221\n",
      "[245]\tTest-rmse:2.39219\n",
      "[246]\tTest-rmse:2.39219\n",
      "[247]\tTest-rmse:2.39219\n",
      "[248]\tTest-rmse:2.39210\n",
      "[249]\tTest-rmse:2.39208\n",
      "[250]\tTest-rmse:2.39207\n",
      "[251]\tTest-rmse:2.39199\n",
      "[252]\tTest-rmse:2.39193\n",
      "[253]\tTest-rmse:2.39192\n",
      "[254]\tTest-rmse:2.39188\n",
      "[255]\tTest-rmse:2.39183\n",
      "[256]\tTest-rmse:2.39179\n",
      "[257]\tTest-rmse:2.39171\n",
      "[258]\tTest-rmse:2.39159\n",
      "[259]\tTest-rmse:2.39156\n",
      "[260]\tTest-rmse:2.39157\n",
      "[261]\tTest-rmse:2.39151\n",
      "[262]\tTest-rmse:2.39146\n",
      "[263]\tTest-rmse:2.39137\n",
      "[264]\tTest-rmse:2.39131\n",
      "[265]\tTest-rmse:2.39132\n",
      "[266]\tTest-rmse:2.39130\n",
      "[267]\tTest-rmse:2.39127\n",
      "[268]\tTest-rmse:2.39119\n",
      "[269]\tTest-rmse:2.39120\n",
      "[270]\tTest-rmse:2.39117\n",
      "[271]\tTest-rmse:2.39114\n",
      "[272]\tTest-rmse:2.39112\n",
      "[273]\tTest-rmse:2.39107\n",
      "[274]\tTest-rmse:2.39104\n",
      "[275]\tTest-rmse:2.39102\n",
      "[276]\tTest-rmse:2.39100\n",
      "[277]\tTest-rmse:2.39100\n",
      "[278]\tTest-rmse:2.39100\n",
      "[279]\tTest-rmse:2.39093\n",
      "[280]\tTest-rmse:2.39089\n",
      "[281]\tTest-rmse:2.39089\n",
      "[282]\tTest-rmse:2.39083\n",
      "[283]\tTest-rmse:2.39081\n",
      "[284]\tTest-rmse:2.39075\n",
      "[285]\tTest-rmse:2.39076\n",
      "[286]\tTest-rmse:2.39070\n",
      "[287]\tTest-rmse:2.39068\n",
      "[288]\tTest-rmse:2.39065\n",
      "[289]\tTest-rmse:2.39061\n",
      "[290]\tTest-rmse:2.39055\n",
      "[291]\tTest-rmse:2.39053\n",
      "[292]\tTest-rmse:2.39051\n",
      "[293]\tTest-rmse:2.39036\n",
      "[294]\tTest-rmse:2.39032\n",
      "[295]\tTest-rmse:2.39025\n",
      "[296]\tTest-rmse:2.39029\n",
      "[297]\tTest-rmse:2.39030\n",
      "[298]\tTest-rmse:2.39027\n",
      "[299]\tTest-rmse:2.39012\n",
      "[300]\tTest-rmse:2.39005\n",
      "[301]\tTest-rmse:2.39010\n",
      "[302]\tTest-rmse:2.39007\n",
      "[303]\tTest-rmse:2.39004\n",
      "[304]\tTest-rmse:2.39004\n",
      "[305]\tTest-rmse:2.38986\n",
      "[306]\tTest-rmse:2.38982\n",
      "[307]\tTest-rmse:2.38983\n",
      "[308]\tTest-rmse:2.38987\n",
      "[309]\tTest-rmse:2.38987\n",
      "[310]\tTest-rmse:2.38982\n",
      "[311]\tTest-rmse:2.38978\n",
      "[312]\tTest-rmse:2.38967\n",
      "[313]\tTest-rmse:2.38961\n",
      "[314]\tTest-rmse:2.38960\n",
      "[315]\tTest-rmse:2.38957\n",
      "[316]\tTest-rmse:2.38948\n",
      "[317]\tTest-rmse:2.38944\n",
      "[318]\tTest-rmse:2.38942\n",
      "[319]\tTest-rmse:2.38932\n",
      "[320]\tTest-rmse:2.38922\n",
      "[321]\tTest-rmse:2.38924\n",
      "[322]\tTest-rmse:2.38919\n",
      "[323]\tTest-rmse:2.38921\n",
      "[324]\tTest-rmse:2.38920\n",
      "[325]\tTest-rmse:2.38918\n",
      "[326]\tTest-rmse:2.38919\n",
      "[327]\tTest-rmse:2.38913\n",
      "[328]\tTest-rmse:2.38906\n",
      "[329]\tTest-rmse:2.38904\n",
      "[330]\tTest-rmse:2.38896\n",
      "[331]\tTest-rmse:2.38897\n",
      "[332]\tTest-rmse:2.38887\n",
      "[333]\tTest-rmse:2.38884\n",
      "[334]\tTest-rmse:2.38886\n",
      "[335]\tTest-rmse:2.38887\n",
      "[336]\tTest-rmse:2.38889\n",
      "[337]\tTest-rmse:2.38896\n",
      "[338]\tTest-rmse:2.38899\n",
      "[339]\tTest-rmse:2.38889\n",
      "[340]\tTest-rmse:2.38882\n",
      "[341]\tTest-rmse:2.38883\n",
      "[342]\tTest-rmse:2.38880\n",
      "[343]\tTest-rmse:2.38875\n",
      "[344]\tTest-rmse:2.38874\n",
      "[345]\tTest-rmse:2.38876\n",
      "[346]\tTest-rmse:2.38877\n",
      "[347]\tTest-rmse:2.38866\n",
      "[348]\tTest-rmse:2.38865\n",
      "[349]\tTest-rmse:2.38859\n",
      "[350]\tTest-rmse:2.38855\n",
      "[351]\tTest-rmse:2.38843\n",
      "[352]\tTest-rmse:2.38841\n",
      "[353]\tTest-rmse:2.38838\n",
      "[354]\tTest-rmse:2.38839\n",
      "[355]\tTest-rmse:2.38840\n",
      "[356]\tTest-rmse:2.38843\n",
      "[357]\tTest-rmse:2.38843\n",
      "[358]\tTest-rmse:2.38843\n",
      "[359]\tTest-rmse:2.38843\n",
      "[360]\tTest-rmse:2.38838\n",
      "[361]\tTest-rmse:2.38836\n",
      "[362]\tTest-rmse:2.38833\n",
      "[363]\tTest-rmse:2.38831\n",
      "[364]\tTest-rmse:2.38826\n",
      "[365]\tTest-rmse:2.38832\n",
      "[366]\tTest-rmse:2.38830\n",
      "[367]\tTest-rmse:2.38832\n",
      "[368]\tTest-rmse:2.38829\n",
      "[369]\tTest-rmse:2.38828\n",
      "[370]\tTest-rmse:2.38836\n",
      "[371]\tTest-rmse:2.38831\n",
      "[372]\tTest-rmse:2.38832\n",
      "[373]\tTest-rmse:2.38832\n"
     ]
    }
   ],
   "source": [
    "# 최종 Test\n",
    "model = xgb.train(\n",
    "    param,\n",
    "    dtrain,\n",
    "    num_boost_round=999,\n",
    "    evals=[(dtest, \"Test\")],\n",
    "    early_stopping_rounds=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 2.39 in 365 rounds\n"
     ]
    }
   ],
   "source": [
    "print(\"Best RMSE: {:.2f} in {} rounds\".format(model.best_score, model.best_iteration+1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# user 정보도 같이 파악하기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가정: 유저 별 평균 등 사용하면 성능이 올라갈 것\n",
    "- 검증 방법: 평균 활용은 biased SVD 를 사용해서 stacking 해보자\n",
    "- 후기: stacking 하다가 중간에 모델을 바꿨는데, feature로 추가하는게 어렵지 않아서 빠르게 해볼걸 그랬다. 다음에 시도하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>year_of_publication</th>\n",
       "      <th>publisher</th>\n",
       "      <th>img_url</th>\n",
       "      <th>language</th>\n",
       "      <th>summary</th>\n",
       "      <th>img_path</th>\n",
       "      <th>category</th>\n",
       "      <th>summary_topic</th>\n",
       "      <th>category_topic</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>4</td>\n",
       "      <td>clara callan</td>\n",
       "      <td>richard bruce wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>collins</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>in a small town in canada clara callan relucta...</td>\n",
       "      <td>images/0002005018.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>074322678X</td>\n",
       "      <td>4</td>\n",
       "      <td>where you ll find me and other stories</td>\n",
       "      <td>ann beattie</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>pocket</td>\n",
       "      <td>http://images.amazon.com/images/P/074322678X.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>now back in print ann beattie 39 s finest shor...</td>\n",
       "      <td>images/074322678X.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0887841740</td>\n",
       "      <td>2</td>\n",
       "      <td>the middle stories</td>\n",
       "      <td>sheila heti</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>harperbusiness</td>\n",
       "      <td>http://images.amazon.com/images/P/0887841740.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/0887841740.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1552041778</td>\n",
       "      <td>2</td>\n",
       "      <td>jane doe</td>\n",
       "      <td>r j kaiser</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>firefly books ltd</td>\n",
       "      <td>http://images.amazon.com/images/P/1552041778.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1552041778.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1567407781</td>\n",
       "      <td>6</td>\n",
       "      <td>the witchfinder amos walker mystery series</td>\n",
       "      <td>loren d estleman</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>llewellyn publications</td>\n",
       "      <td>http://images.amazon.com/images/P/1567407781.0...</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>images/1567407781.01.THUMBZZZ.jpg</td>\n",
       "      <td>fiction1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>timmins,ontario,canada</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        isbn  rating                                  book_title  \\\n",
       "0        8  0002005018       4                                clara callan   \n",
       "1        8  074322678X       4      where you ll find me and other stories   \n",
       "2        8  0887841740       2                          the middle stories   \n",
       "3        8  1552041778       2                                    jane doe   \n",
       "4        8  1567407781       6  the witchfinder amos walker mystery series   \n",
       "\n",
       "            book_author  year_of_publication               publisher  \\\n",
       "0  richard bruce wright               2001.0                 collins   \n",
       "1           ann beattie               2002.0                  pocket   \n",
       "2           sheila heti               2004.0          harperbusiness   \n",
       "3            r j kaiser               1999.0       firefly books ltd   \n",
       "4      loren d estleman               1998.0  llewellyn publications   \n",
       "\n",
       "                                             img_url language  \\\n",
       "0  http://images.amazon.com/images/P/0002005018.0...       en   \n",
       "1  http://images.amazon.com/images/P/074322678X.0...       en   \n",
       "2  http://images.amazon.com/images/P/0887841740.0...       en   \n",
       "3  http://images.amazon.com/images/P/1552041778.0...       en   \n",
       "4  http://images.amazon.com/images/P/1567407781.0...       en   \n",
       "\n",
       "                                             summary  \\\n",
       "0  in a small town in canada clara callan relucta...   \n",
       "1  now back in print ann beattie 39 s finest shor...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                            img_path  category  summary_topic  category_topic  \\\n",
       "0  images/0002005018.01.THUMBZZZ.jpg  fiction1           -1.0           108.0   \n",
       "1  images/074322678X.01.THUMBZZZ.jpg  fiction1           -1.0            33.0   \n",
       "2  images/0887841740.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "3  images/1552041778.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "4  images/1567407781.01.THUMBZZZ.jpg  fiction1            NaN             NaN   \n",
       "\n",
       "                 location   age  \n",
       "0  timmins,ontario,canada  32.0  \n",
       "1  timmins,ontario,canada  32.0  \n",
       "2  timmins,ontario,canada  32.0  \n",
       "3  timmins,ontario,canada  32.0  \n",
       "4  timmins,ontario,canada  32.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                 59803\n",
       "isbn                   129777\n",
       "rating                     10\n",
       "book_title             115473\n",
       "book_author             52679\n",
       "year_of_publication        92\n",
       "publisher                1402\n",
       "img_url                129777\n",
       "language                   24\n",
       "summary                 69758\n",
       "img_path               129777\n",
       "category                   15\n",
       "summary_topic             350\n",
       "category_topic            112\n",
       "location                13888\n",
       "age                        91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
